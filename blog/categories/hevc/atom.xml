<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类:hevc | 懒人李冰]]></title>
  <link href="http://lazybing.github.io/blog/categories/hevc/atom.xml" rel="self"/>
  <link href="http://lazybing.github.io/"/>
  <updated>2021-11-07T07:22:14-08:00</updated>
  <id>http://lazybing.github.io/</id>
  <author>
    <name><![CDATA[李冰]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OverView of HEVC Standard]]></title>
    <link href="http://lazybing.github.io/blog/2021/10/16/overview-of-hevc-stand/"/>
    <updated>2021-10-16T06:48:21-07:00</updated>
    <id>http://lazybing.github.io/blog/2021/10/16/overview-of-hevc-stand</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">介绍</a></li>
  <li><a href="#hevc-" id="markdown-toc-hevc-">HEVC 编码设计和功能亮点</a>    <ul>
      <li><a href="#a-" id="markdown-toc-a-">A. 视频编码层</a>        <ul>
          <li><a href="#coding-tree-units-and-coding-tree-blockctb-structure" id="markdown-toc-coding-tree-units-and-coding-tree-blockctb-structure">1) Coding tree units and coding tree block(CTB) structure</a></li>
          <li><a href="#coding-unitscus-and-coding-blockscbs" id="markdown-toc-coding-unitscus-and-coding-blockscbs">2）Coding units(CUs) and coding blocks(CBs)</a></li>
          <li><a href="#prediction-units-and-prediction-blockspbs" id="markdown-toc-prediction-units-and-prediction-blockspbs">3）Prediction units and prediction blocks(PBs)</a></li>
          <li><a href="#tus-and-transform-blocks" id="markdown-toc-tus-and-transform-blocks">4）TUs and transform blocks</a></li>
          <li><a href="#motion-vector-signaling" id="markdown-toc-motion-vector-signaling">5）Motion vector signaling</a></li>
          <li><a href="#motion-compensation" id="markdown-toc-motion-compensation">6）Motion compensation</a></li>
          <li><a href="#intrapicture-prediction" id="markdown-toc-intrapicture-prediction">7) Intrapicture prediction</a></li>
          <li><a href="#quantization-control" id="markdown-toc-quantization-control">8) Quantization control</a></li>
          <li><a href="#entropy-coding" id="markdown-toc-entropy-coding">9）Entropy coding</a></li>
          <li><a href="#in-loop-deblocking-filtering" id="markdown-toc-in-loop-deblocking-filtering">10）In-loop deblocking filtering</a></li>
          <li><a href="#sample-adaptive-offsetsao" id="markdown-toc-sample-adaptive-offsetsao">11）Sample adaptive offset(SAO)</a></li>
        </ul>
      </li>
      <li><a href="#b-" id="markdown-toc-b-">B. 高级语法体系结构</a>        <ul>
          <li><a href="#parameter-set-structure" id="markdown-toc-parameter-set-structure">1）Parameter set structure</a></li>
          <li><a href="#nal-unit-syntax-structure" id="markdown-toc-nal-unit-syntax-structure">2）NAL unit syntax structure</a></li>
          <li><a href="#slices" id="markdown-toc-slices">3）Slices</a></li>
          <li><a href="#sei--vui" id="markdown-toc-sei--vui">4）SEI 和 VUI</a></li>
        </ul>
      </li>
      <li><a href="#c--slice-" id="markdown-toc-c--slice-">C. 并行解码语法与改进的 slice 结构</a>        <ul>
          <li><a href="#tiles" id="markdown-toc-tiles">1） Tiles</a></li>
          <li><a href="#wavefront-parallel-processingwpp" id="markdown-toc-wavefront-parallel-processingwpp">2）Wavefront parallel processing(WPP)</a></li>
          <li><a href="#dependent-slice-segments" id="markdown-toc-dependent-slice-segments">3）Dependent slice segments</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#section-1" id="markdown-toc-section-1">高级语法</a>    <ul>
      <li><a href="#a-random-access-and-bitstream-splicing-features" id="markdown-toc-a-random-access-and-bitstream-splicing-features">A) Random Access and Bitstream Splicing Features</a></li>
      <li><a href="#b-temporal-sublayering-support" id="markdown-toc-b-temporal-sublayering-support">B) Temporal Sublayering Support</a></li>
      <li><a href="#c-additional-parameter-sets" id="markdown-toc-c-additional-parameter-sets">C) Additional Parameter Sets</a></li>
      <li><a href="#d-reference-picture-sets-and-reference-picture-lists" id="markdown-toc-d-reference-picture-sets-and-reference-picture-lists">D) Reference Picture Sets and Reference Picture Lists</a></li>
    </ul>
  </li>
  <li><a href="#hevc--1" id="markdown-toc-hevc--1">HEVC 视频编码技术</a>    <ul>
      <li><a href="#a-sampled-representation-of-pictures" id="markdown-toc-a-sampled-representation-of-pictures">A) Sampled Representation of Pictures</a></li>
      <li><a href="#b-division-of-the-picture-into-coding-tree-unit" id="markdown-toc-b-division-of-the-picture-into-coding-tree-unit">B) Division of the Picture into Coding Tree Unit</a></li>
      <li><a href="#c-division-of-the-ctb-into-cbs" id="markdown-toc-c-division-of-the-ctb-into-cbs">C) Division of the CTB into CBs</a></li>
      <li><a href="#d-pbs-and-pus" id="markdown-toc-d-pbs-and-pus">D) PBs and PUs</a></li>
      <li><a href="#e-tree-structured-partitioning-into-transform-blocks-and-units" id="markdown-toc-e-tree-structured-partitioning-into-transform-blocks-and-units">E) Tree-Structured Partitioning Into Transform Blocks and Units</a></li>
    </ul>
  </li>
</ul>

<p>HEVC 是 ITU-T 视频编码专家组和 ISO/IEC 运动图像专家组的最新视频编码标准。HEVC 标准化工作的主要目标是相对于现有标准，在 50% 的比特率降低范围内显著提高压缩性能，以获得相同的感知视频质量。本文概述了 HEVC 标准的技术特性和特点。</p>

<!--more-->

<h2 id="section">介绍</h2>

<p>HEVC 标准是 ITU-T 视频编码专家组(VCEG)和 ISO/IEC 运动图像专家组(MPEG)标准化组织的最新联合视频项目，它们在一个称为视频编码联合协助小组(JCT-VC)的伙伴组织关系中共同工作。HEVC 标准的第一版预计将于 2013 年 1 月定稿，最终形成一份由 ITU-T 和 ISO/IEC 共同发布的统一文本。后续会有更多工作，以扩展该标准，从而支持多个其他应用场景，包括具有增强精度和颜色格式支持的扩展范围使用、可伸缩视频编码和三维/立体/多视图视频编码。在 ISO/IEC 中，HEVC标准将成为 MPEG-H 第 2 部分(ISO/IEC 23008-2)，在 ITU-T 中，它很可能成为 ITU-T 建议 H.265。</p>

<p>视频编码标准主要通过注明的 ITU-T 和 ISO/IEC 标准的发展而起来的。ITU-T 生产了 H.261 和 H.263，ISO/IEC 生产了 MPEG-1 和 MPEG-4视频，这两个组织联合生产了 H.262/MPEG-2视频和 H.264/MPEG-4 AVC 标准。这两项联合制定的标准产生了特别强烈的影响，并已被广泛应用于我们日常生活中日益流行的各种产品中。在这一演变过程中，不断努力最大限度地提高压缩能力，并改进其他特性，如数据丢失鲁棒性，同时考虑到在预期部署每个标准时，产品中实际使用的计算资源。</p>

<p>HEVC 之前的主要视频编码标准是 H.264/MPEG-4 AVC，它最初是在 1999 年至 2003 年期间开发的，然后在 2003 年至 2009 年期间以几种重要方式进行了扩展。H.264/MPEG-4 AVC 是数字视频的一种使能技术，几乎涵盖了 H.262/MPEG-2 视频之前未涵盖的所有领域，并在其现有应用领域中基本上取代了旧标准。它广泛应用于许多应用，包括通过卫星、有线和地面传输系统广播高清(HD)电视信号、视频内容采集和编辑系统、摄像机、安全应用、互联网和移动网络视频、蓝光光盘以及视频聊天等实时对话应用，视频会议和远程呈现系统。</p>

<p>然而，服务的日益多样化、高清视频的日益普及以及超高清格式(如4kx2k 或 8kx4k分辨率)的出现，对编码效率的需求甚至超出了 H.264/MPEG-4 AVC 的能力。当更高的分辨率伴随立体声或多视图捕获和显示时，这种需求更强烈了。此外，针对移动设备和平板电脑的视频应用程序所带来的流量，以及视频点播服务的传输需求，正在给当今的网络带来严峻挑战。在移动应用程序中，对更高质量和分辨率的需求也越来越强烈。</p>

<p>HEVC 旨在解决 H.264/AVC 的所有现有应用，并特别关注两个特别问题：提高视频分辨率，增加并行处理框架的使用。HEVC 的语法是通用的，通常也适用于上面没有特别提到的其他应用程序。</p>

<p>与过去所有的 ITU-T 和 ISO/IEC 视频编码标准一样，在 HEVC 中，只有比特流结构和语法是标准化的，并且对生产解码图片的比特流及其映射的约束也是标准化的。通过定义语法元素的语义和解码过程来给出映射，使得当给定符合标准约束的比特流时，符合标准的每个解码器将产生相同的输出。标准范围的这种限制允许以适合特定应用的方式(平衡压缩质量、实现成本、上市时间和其他考虑因素)最大限度地优化实现。然而，它并不能保证端到端的复制质量，因为它甚至允许有损失的编码技术被认为是合格的。</p>

<p>为了帮助行业社区学习如何使用标准，标准化工作不仅包括开发文本规范文档，还包括参考软件源代码，作为如何编码和解码 HEVC 视频的示例。在标准设计期间，参考软件草案已被用作委员会内部工作的研究工具，也可作为通用研究工具和产品基础，还正在开发标准测试数据套件，以测试是否符合该标准。</p>

<p>本文的组织结构如下：第二部分重点介绍 HEVC 编码设计的一些关键特性。第三部分解释了 HEVC 编码数据的高级语法和总体结构。第四部分将更详细地描述 HEVC 编码技术。第五部分解释了 HEVC 的 profile、tier 和 level 设计。由于编写像  HEVC 这样实质性的技术概述需要大量的总结，如有遗漏，请向读者咨询。第六部分讨论了 HEVC 标准化工作的历史。</p>

<h2 id="hevc-">HEVC 编码设计和功能亮点</h2>

<p>HEVC 标准旨在实现多个目标，包括编码效率、易于传输系统集成和数据丢失恢复能力，以及使用并行处理架构的可实现性。下面小节简要描述了实现这些目标的设计关键要素，以及生成有效比特流的典型编码器操作。第三节和第四节提供了有关不同元素的相关语法和解码过程的更多细节。</p>

<h3 id="a-">A. 视频编码层</h3>

<p>HEVC 的视频编码层采用自 H.261 以来所有视频压缩标准中使用的相同的混合编码方法(图像间/图像内预测和二维变换编码)。图 1 描述了可创建符合 HEVC 标准的比特流的混合视频编码器的框图。</p>

<p>产生符合 HEVC 的比特流的编码算法通常如下进行：每个图片被分割成块形区域，精确的块分割被传送到解码器。视频序列的第一幅图片(以及每个随机接入点处的第一幅图片到视频序列中)仅使用图片内预测进行编码(该预测使用同一图片内从区域到区域的空间数据预测，但不依赖于其他图片)。对于序列或随机接入点间的所有剩余图片，通常对大多数块使用图像间时间预测编码模式。用于画面间预测的编码处理包括：选择包含所选参考画面和运动矢量(MV)的运动数据，以应用于预测每个块的样本。编码器和解码器通过使用 MV 和模式决策数据应用运动补偿(MC)来生成相同的图像间预测信号，这些数据作为边信息传输。</p>

<p>帧内或帧间预测的残余信号(即原始块与其预测之间的差值)，通过线性空间变换进行变换。然后对变换系数进行缩放、量化、熵编码，并与预测信心一起传输。</p>

<p>编码器复制解码器处理循环(参见图1中的灰色阴影框)，以便两者将为后续数据生成相同的预测。因此，量化变换系数通过逆缩放构造，然后逆变换以复制剩余信号的解码近似。然后将残差添加到预测中，并且该添加的结果随后可被反馈到一个或两个环路滤波器中以平滑由分块处理和量化引起的伪影。最终图片表示(即解码器输出的副本)存储在解码图片缓冲器中，以用于后续图片的预测。一般来说，图片的编码或解码处理顺序通常不同于它们从源到达的顺序，需要区分解码器的解码顺序(即比特流顺序)和输出顺序(即显示顺序)。</p>

<p>要由 HEVC 编码的视频材料通常应作为逐行扫描图像输入(由于源视频以该格式产生，或由编码前去交错)。HEVC 设计中不存在明确的编码特征，以支持隔行扫描的使用，因为隔行扫描不再用于显示，并且在分发中变得越来越步常见。然而，在 HEVC 中提供了元数据语法，以允许编码器通过将隔行扫描视频的每个字段(即，每个视频帧的偶数或奇数行)编码以单独图片来指示隔行扫描视频已被发送，或这其已通过将每个隔行扫描帧编码为 HEVC 编码图片来发送。这提供了一种对隔行视频进行编码的有效方法，而无需使解码器负担对其支持特殊解码过程的负担。</p>

<p>在下文中，使用 HEVC 的混合视频编码所涉及的各种特性如下所示。</p>

<h4 id="coding-tree-units-and-coding-tree-blockctb-structure">1) Coding tree units and coding tree block(CTB) structure</h4>

<p>在以前的标准中，编码层的核心是宏块，它包含 luma 采样的 16x16 宏块，在通常的 4:2:0 颜色采样情况下，chroma 采样有对应的 8x8 色度块；而 HEVC 中的类似结构是编码树单元(CTU)，其大小由编码器选择，可以大于传统宏块。CTU 由 luma CTB 和对应的色度 CTB 以及语法元素组成。luma CTB 的大小可以选择为 L=16、32或64个样本，较大的大小通常能够实现更好的压缩。HEVC 支持使用树结构和类似四叉树的信令将 CTB 划分为更小的块。</p>

<h4 id="coding-unitscus-and-coding-blockscbs">2）Coding units(CUs) and coding blocks(CBs)</h4>

<p>CTU 的四叉树语法指定其亮度和色度 CBs 的大小和位置。四叉树的根与 CTU 关联。因此，luma CTB 的大小是 luma CB 支持的最大大小。CTU 分为 luma 和 chroma CBs 是联合发出的信号。一个 luma CB 和两个 sample CB，连同相关的语法，构成一个编码单元(CU)。一个 CTB 可以只包含一个 CU，或者可以分割成多个 CU，并且每个 CU 都有一个相关的分区为预测单元(PU)和变换单元树(TU)。</p>

<h4 id="prediction-units-and-prediction-blockspbs">3）Prediction units and prediction blocks(PBs)</h4>

<p>在 CU 级别决定是使用图像间预测还是图像内预测对图片区域进行编码。PU 分区结构的根位于 CU 级别。取决于基本预测类型决策，luma 和 chroma CBs 随后可以在大小上进一步分割并从 luma 和 chroma 预测块(PBs)预测。HEVC 支持从 64x64 到 4x4 样本的可变 PB 大小。</p>

<h4 id="tus-and-transform-blocks">4）TUs and transform blocks</h4>

<p>使用块变换对预测残差进行编码。TU 树结构的根位于 CU 级别。luma CB 残差可以与 luma 变换块(TB)相同，或者可以进一步分割成更小的 luma TB。这同样适用于 chroma TBs。对于 4x4、8x8、16x16 和 32x32 的正方形 TB，定义了与DCT 类似的整数基函数。对于 luma 图像内预测残差的 4x4 变换，可选指定从 DST 形式导出的整数变换。</p>

<h4 id="motion-vector-signaling">5）Motion vector signaling</h4>

<p>使用AMVP(Advanced motion vector prediction)，包括基于来自相邻 PBs 和参考图片的数据导出几个最可能的候选。还使用 MV 编码的合并模式，允许 MV 从时间上或空间上相邻的 PBs 继承。此外，与 H.264/AVC 相比，还指定了改进的 skipped 和 直接运动推断。</p>

<h4 id="motion-compensation">6）Motion compensation</h4>

<p>MVs 使用四分之一采样精度，分数采样位置的插值使用 7 抽头或 8 抽头滤波器(相比之下，H.264/AVC 中，半采样位置的六抽头滤波后，四分之一采样位置的线性插值)。与 H.264/AVC 类似，使用了多个参考图片。对于每个 PB，传输一个或两个运动矢量，分别表示单预测或双预测编码。如在 H.264/AVC 中一样，可以称为加权预测的方式对预测信号应用缩放和偏移操作。</p>

<h4 id="intrapicture-prediction">7) Intrapicture prediction</h4>

<p>相邻块的间边界样本，用作未执行帧间预测的区域中的空间预测的参考数据。图像内预测支持 33 种方向模式(与 H.264/AVC 中的 8 种模式相比)，以及plus plannr 和 DC 预测模式。通过基于先前解码的相邻 PBs 的模式导出最可能模式(例如，预测方向)来编码所选择的画面内预测模式。</p>

<h4 id="quantization-control">8) Quantization control</h4>

<p>与 H.264/AVC 中一样，HEVC 中使用均匀重建量化(URQ)，量化缩放矩阵支持各种变换块大小。</p>

<h4 id="entropy-coding">9）Entropy coding</h4>

<p>CABAC 用于熵编码。这类似于 H.264/AVC 中的 CABAC 方案，单经过几次改进以提高其吞吐量速度(特别是对于并行处理架构)和压缩性能，并降低其上下文内存需求。</p>

<h4 id="in-loop-deblocking-filtering">10）In-loop deblocking filtering</h4>

<p>与 H.264/AVC 中使用的去块滤波器类似去块滤波器，在图像间预测循环中操作。然而，该设计在决策和过滤过程方面得到了简化，并且对并行处理更加友好。</p>

<h4 id="sample-adaptive-offsetsao">11）Sample adaptive offset(SAO)</h4>

<p>在去块滤波器之后，在图像间预测环路中引入非线性振幅映射。它的目标是通过使用查找表更好地重建原始信号振幅，该查找表由几个附加参数描述，这些参数可以通过编码器端的直方图分析确定。</p>

<h3 id="b-">B. 高级语法体系结构</h3>

<p>HEVC 标准新增的许多设计方面，提高了在各种应用程序和网络环境下操作的灵活性，并提高了数据丢失的鲁棒性。然而，H.264/AVC 标准中使用的高级语法体系结构通常被保留，包括以下特征。</p>

<h4 id="parameter-set-structure">1）Parameter set structure</h4>

<p>参数集包含可共享的信息，用于解码解码视频的多个区域。参数集结构提供了用于传输解码过程所必需的数据的健壮机制。通过一种新的 VPS 结构，对 H.264/AVC 中的序列和图片参数集的概念进行了扩充。</p>

<h4 id="nal-unit-syntax-structure">2）NAL unit syntax structure</h4>

<p>每个语法结构都被放入 NAL 单元的逻辑数据包中。使用两个字节 NAL 单元报头的内容，可以容易地识别相关有效负载数据的用途。</p>

<h4 id="slices">3）Slices</h4>

<p>slice 是一种数据结构，在熵编码、信号预测和残差信号重建方面，可以独立于同一图片的其他 slice 进行解码。slice 可以是整个图片，也可以是图片中的一个区域。slice 的主要用途之一是在数据丢失时重新同步。在分组传输的情况下， slice 内有效负载比特的最大数量通常受到限制，并且 slice 中 CTU 的数量经常变化以最小化分组开销，同时将每个分组的大小保持在此范围内。</p>

<h4 id="sei--vui">4）SEI 和 VUI</h4>

<p>该语法元素支持各种类型元数据，比如 SEI 和 VUI。这些数据提供关于视频图片的定时、视频信号中使用的颜色空间的正确解释、三维立体帧打包信息、其他显示提示信息等的信息。</p>

<h3 id="c--slice-">C. 并行解码语法与改进的 slice 结构</h3>

<p>最后，HEVC 标准中引入了四个新的特性，以增强并行处理能力或修改 slice 数据的结构以实现打包。它们中的每一个在特定的应用环境中都可能有好处，并且通常由编码器或解码器的实现者来确定是否以及如何利用这些特性。</p>

<h4 id="tiles">1） Tiles</h4>

<p>Tiles 作为标准的可选项，它将图片分割为矩形区域。Tiles 的主要目的是增加并行处理能力，而不是提供错误恢复能力。Tiles 是图片的独立可解码区域，它使用一些共享头信息进行编码。Tiles 还可用于视频图片局部区域的空间随机访问。图片的典型 tile 配置将图片分割为矩形区域，每个 tiles 中的 CTU 数量大致相等。Tiles 提供了并行性的更粗粒度级别，并且线程的使用不需要复杂的同步。</p>

<h4 id="wavefront-parallel-processingwpp">2）Wavefront parallel processing(WPP)</h4>

<p>当启动波前并行处理(WPP)时，一个 slice 被划分为若干行 CTU。第一行以普通方式处理，第二行可以在第一行仅处理两个 CTU 后开始处理，第三行可以在第二行仅处理两个 CTU 后开始处理，以此类推。每一行中熵编码器的上下文模型是根据前一行中具有两个 CTU 处理延迟的上下文模型推到出来的。WPP 在相当精细的粒度级别上提供了一种处理并行性的形式，即在一个 slice 内。WPP 通常可以提供比 Tiles 更好的压缩性能(并避免使用 Tiles 可能导致的一些视觉瑕疵)。</p>

<h4 id="dependent-slice-segments">3）Dependent slice segments</h4>

<p>一种称为 Dependent Slice Segment 的结构，允许在单独的 NAL 单元中携带与特定波前入口点或 Tiles 相关的数据，因此，与将数据全部编码在一个 slice 中相比，该结构有可能使该数据以更低的延迟提供给分片打包系统。波前入口点的 Dependent Slice Segments 只能在另一 slice 的解码过程的至少一部分已经执行之后进行解码。相关 slice 主要用于低延迟编码，其他并行工具可能会影响压缩性能。</p>

<p>接下来的两个部分中，将对主要功能进行更详细的描述。</p>

<h2 id="section-1">高级语法</h2>

<p>HEVC 的高级语法包含许多继承自 H.264/AVC NAL 的元素。NAL 提供将表示图片内容的视频编码层(VCL)数据映射到各种传输层(包括RTP/IP，ISO MP4 和 H.222.0/MPEG-2系统)的能力，并提供分组丢失恢复的框架。有关 NAL 设计的一般概念，如 NAL 单元、参数集、访问单元、字节流格式和分组格式，请参考[9]-[11]。</p>

<p>根据是否包含编码图片或其他相关数据，NAL 单元分为 VCL 和 非 VCL NAL 单元。HEVC 标准中，包括几种用于识别用于解码器初始化和随机访问目的的图片类型的 VCL NAL 单元类型。表 I 列出了 HEVC 标准中的 NAL 单元类型及其相关含义和类型类别。</p>

<p>以下小节介绍了高级语法支持的新功能。</p>

<h3 id="a-random-access-and-bitstream-splicing-features">A) Random Access and Bitstream Splicing Features</h3>

<p>HEVC 新设计支持特殊功能以实现随机访问和比特流拼接。在 H.264/AVC 中，比特流必须始终以 IDR 访问单元开始。IDR 访问单元包含独立编码的图片，即，可以在不解码 NAL 单元流中的任何先前图片的情况下解码的编码图片。IDR 访问单元的存在指示，比特流中的后续图片将不需要参考其包含的图片之前的图片以便被解码。IDR 图片在称为闭合 GOP(其中 GOP 代表图片组)的编码结构内使用。</p>

<p>新的 CRA(Clean Random Access) 图片语法指定在 RAP(Random Access Point)的位置处使用独立编码的图片。即，在比特流中解码器可以开始成功解码图片的位置处，而无需解码比特流中先前出现的任何图片，它支持一种称为开放 GOP 操作的高效时间编码顺序。对 RAP 的良好支持，对于启用通道切换、搜索操作和动态流媒体服务至关重要。按照解码顺序在 CRA 图像之后，按显示顺序在 CRA 图像之前的图片，可能包含对解码器处不可用的图片的帧间预测参考。因此，在 CRA 点开始解码过程的解码器，必须丢弃这些不可解码的图像。为此，此类不可解码图片被标识为 RASL（Random Access Skipped Leading）图片。来自不同编码比特流的拼接点位置可通过 BLA(Broken Link Access)图片指导。比特流拼接操作可以通过简单地将一个比特流中 CRA 图片的 NAL 单元类型更改为指示 BLA 图片的值，并将新比特流连接到另一个比特流中 RAP 图片的位置来执行。RAP 图像可能是 IDR、CRA 或 BLA 图像，并且 CRA 和 BLA 图像之后可以是比特流中的 RASL 图片(取决于用于 BLA 图片的 NAL 单元类型的特定值)。解码器必须始终丢弃与 BLA 图片相关联的任何 RASL 图片，因为它们可能包含对由于拼接操作而实际不存在于比特流中的图片的参考。另一种可以以解码顺序跟随 RAP 图片之后，并在以输出顺序在 RAP 之前的图片类型，是RADL(Random Access Decodable Leading)图片，其不能包含对以解码顺序在 RAP 图片之前的任何图片的参考。RASL 和 RADL 图片统称为 Leading Pictures.以解码顺序和输出顺序跟随在 RAP 图片之后的图像(称为 Trailing Picture)不能包含对用于图片间预测的 Leading Picture 的参考。</p>

<h3 id="b-temporal-sublayering-support">B) Temporal Sublayering Support</h3>

<p>与 H.264/AVC 可伸缩视频编码(SVC)扩展中的时间可伸缩性特征类似，HEVC 在 NAL 单元报头中指定了时间标识符，其指示分层时间预测结构中的级别。这是为了实现时间可伸缩性，而无需解析除 NAL 单元以外的比特流部分。</p>

<p>在某些情况下，在一个编码视频序列的解码过程中，解码时间子层的数量是可以调整的。比特流中的点(此点位置是发生子层切换，可以开始解码一些更高级时间层的点)可以通过TSA(Temporal Sublayer Access)图片和STSA(StepWise TSA)图片的存在来指示。在 TSA 图像的位置，可以从解码较低的时间子层切换到解码任何较高时间子层；在 STSA 图像位置，可以从解码较低时间子层切换到仅解码一个特定较高时间子层(但不包括上面的其他层，除非它们还包含 STSA 或 TSA 图像)；</p>

<h3 id="c-additional-parameter-sets">C) Additional Parameter Sets</h3>

<p>VPS 已添加为元数据，已描述编码视频序列的总体特征，包括时间子层之间的依赖关系。其主要目的是实现标准在系统层的信令方面的兼容扩展性，例如，当未来扩展的可伸缩或多视图比特流的基本层需要由传统解码器解码时。但是，对于这种情况，只与高级解码器相关的关于比特流结构的附加信息将被忽略。</p>

<h3 id="d-reference-picture-sets-and-reference-picture-lists">D) Reference Picture Sets and Reference Picture Lists</h3>

<p>对于多参考图片管理，解码图片缓冲区(DPB)中需要存在一组特定的先前解码图片，用于解码比特流中的其余图片。为了标识这些图片，在每个片头中传输图片顺序计算(POC)标识符的列表。保留的参考图片集称为 RPS。图2示出了用于示例性时间预测结构的 POC 值、解码顺序和 RPS。</p>

<p>与 H.264/AVC 中一样，有两个列表被构造为 DPB 中的图片列表，它们被称为参考图片列表 0 和 列表 1。称为参考图片索引的索引用于识别这些列表之一中的特定图片。对于单预测，可以从这些列表中选择图片。对于双向预测，将从每个列表中选择两张图片。当列表仅包含一个图片时，参考图片索引隐士地具有值 0，并且不需要在比特流中传输。</p>

<p>与先前的 H.264/AVC 设计相比，用于识别 RPS 和建立用于画面间预测的参考图片列表的高级语法对数据丢失更为鲁棒，并且更适于诸如随机访问和技巧模式操作之类的操作(例如，快进、平滑倒带、搜索和自适应比特流切换)。这些改进的一个关键方面是语法更加明确，而不是依赖于解码过程中存储的内部状态的推断，因为它逐帧解码比特流。此外，设计的这些方面的相关语法实际上比 H.264/AVC 更简单。</p>

<h2 id="hevc--1">HEVC 视频编码技术</h2>

<p>与 H.261 以来所有先前的 ITU-T 和 ISO/IEC JTC 1 视频编码标准一样，HEVC 设计遵循经典的基于块的混合视频编码方法(如图1所示)。基于信源编码算法是利用时间统计相关性的帧间预测、利用空间统计相关性的帧内预测和利用空间统计相关性的预测残差信号的变换编码的混合。与先前的视频编码标准相比，HEVC 设计中没有一个编码元素能够显著提高压缩效率。更确切地说，是多个较小的改进增加了显著的收益。</p>

<h3 id="a-sampled-representation-of-pictures">A) Sampled Representation of Pictures</h3>

<p>为了表示彩色视频信号，HEVC 通常使用具有4:2:0 采样的 YCbCr 颜色空间(尽管扩展到其他采样格式很简单，计划在后续版本中定义)。这将颜色表示为三个组件，分别称为Y、Cb 和 Cr。Y 组件也称为亮度，表示亮度。两个色度分量Cb 和 Cr 分别表示颜色从灰色向蓝色和红色的偏离程度。由于人类视觉系统对亮度比色度更敏感，因此通常使用4：2：0采样结构，其中每个色度分量具有亮度分量样本数的四分之一(水平和垂直维度样本数的一半)。每二个组件的每个样本通常以 8 或 10 bit的精度表示，8 bit的情况更为典型。在本文的其余部分中，我们将重点放在典型用途上:YCbCr 组件具有4：2：0采样和 8bit 每个采样，用于表示编码输入和解码输出视频信号。</p>

<p>视频图像通常以矩形图片大小WxH逐步采样，其中 W 是宽度，H 是 luma 样本中图片的高度。采用4：2：0采样的每个色度分量阵列为W/2xH/2。给定这样的视频信号，HEVC 语法进一步划分图片，如下所述。</p>

<h3 id="b-division-of-the-picture-into-coding-tree-unit">B) Division of the Picture into Coding Tree Unit</h3>

<p>图片被划分成编码树单元(CTU)，每个单元包含亮度 CTB 和色度 CTB。亮度 CTB 覆盖亮度分量的 LxL 样本的矩形图像区域，相应的色度 CTB 覆盖两个色度分量中每个分量的 L/2xL/2 样本。L 的值可以是 16、32、64，由 SPS 中指定的编码语法元素确定。与传统宏块相比，HEVC 支持根据编码器在内存和计算需求方面的需求，选择可变大小的 CTB。而从 H.261 以来所有先前的 ITU-T 和 ISO/IEC JTC 视频编码标准中，宏块使用固定阵列大小的 16x16 luma 样本。在编码高分辨率视频内容时，支持以前的标准更大的 CTB 尤其有益。luma  CTB 和两个色度 CTB 以及相关的语法构成了CTU。CTU 是标准中用于指定解码过程的基本处理单元。</p>

<h3 id="c-division-of-the-ctb-into-cbs">C) Division of the CTB into CBs</h3>

<p>指定为 luma 和 chroma CTB 的块可以直接用作 CB，或者可以进一步划分为多个 CB，划分是使用树形结构实现的。HEVC 中的树划分通常同时应用于亮度和色度，但当色度达到某些最小值时例外。</p>

<p>CTU 包含四叉树语法，该语法允许根据 CTB 覆盖区域的信号特征，将 CBs 划分为选定的合适大小。四叉树划分过程可以迭代，直到 luma CB 的大小达到所允许的最小luma CB 大小。该最小 luma CB 大小是编码器使用 SPS 中的语法元素指定选择的，它始终为 8x8 或更大(以 luma 样本为单位)。</p>

<p>图片的边界以允许的最小 luma CB 大小为单位定义。因此，在图片的右边缘和下边缘，一些 CTU 可能会覆盖部分位于图片边界之外的区域。解码器检测到这种情况，并根据需要隐士分割 CTU 四叉树，以将 CB 大小减小到整个 CB 将适合图片的位置。</p>

<h3 id="d-pbs-and-pus">D) PBs and PUs</h3>

<p>根据 CU 使用的是画面内预测还是画面间预测，CU 的预测模式用信号表示为帧内预测或帧间预测。</p>

<p>当预测模式是帧内模式时，PU 大小（即建立图像内预测模式时的块大小）与所有块大小的 CB 大小相同。但比特流中允许的最小 CB 大小除外。对于后一种情况，存在一个标志，指示 CB 是否被分成四个 PB 象限，每个象限都有自己的帧内预测模式。允许这种分割的原因是为大小 4x4 的块启用不同的帧内预测模式选择。当亮度帧内预测使用 4x4 块进行操作时，色度帧内预测也使用 4x4 块(每个块覆盖与四个 4x4 亮度块相同的图片区域)。帧内预测操作时的实际区域大小(与建立帧内预测模式时的 PB 大小不同)取决于如下所述的剩余编码分区。</p>

<p>当预测模式是帧间时，指定亮度和色度 CBs 是否被分割成一个、两个或四个 PBs。仅当 CB 尺寸等于允许的最小 CB 尺寸时，才允许将 CB 分为四个 PBs，使用等效类型的拆分，否则可在设计的 CB 级而不是 PB 级执行拆分。当 CB 被划分为四个 PBs 时，每个 PB 覆盖 CB 的一个角；当 CB 被划分为两个 PBs 时，可能会出现六种不同的划分。图 3 描述了帧间预测的 CBs 的划分可能性。图中的上半部分说明了划分大小为 MxM 的 CB，将 CB 划分为大小为 MxM/2 或 M/2xM 的两个 PBs，将其划分为大小为 M/2xM/2 的四个 PBs 的情况。图 3 中下半部分的四种划分类型被称为非对称运动分区(AMP)，并且仅在 luma 的 M 为 16 或更大时才允许。不对称划分的一个 PB 的高度或宽度分别为 M/4 和 M，另一个 PB 的高度或宽度分别为 3M/4 和 M，填充 CB 的其余部分。每个帧间预测 PB 被分配一个或两个运动矢量和参考图片索引。为了最小化最坏情况下的内存带宽，不允许使用 luma 大小为 4x4 的 PBs 进行帧间预测，并且 luma 大小为 4x8 和 8x4 的 PBs 仅限于单预测编码。下面进一步描述帧间预测处理。</p>

<p>luma 和 chroma PBs，以及相关的预测语法构成 PU。</p>

<h3 id="e-tree-structured-partitioning-into-transform-blocks-and-units">E) Tree-Structured Partitioning Into Transform Blocks and Units</h3>

<p>对于残差编码，CB 可以递归地划分为 TBs(Transform Blocks)。划分由残差四叉树表示。</p>

<p>如图 4 所示，仅指定方形 CB 和 TB 分区，其中块可以递归地分割为四象限。对于给定大小的 MxM 的 luma CB，一个标志表示它是否被划分为大小为 M/2xM/2 的四个块。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC学习之RPS(待整理)]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/27/hevc-rps/"/>
    <updated>2016-11-27T06:20:37-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/27/hevc-rps</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#hevc-spec-rps" id="markdown-toc-hevc-spec-rps">HEVC SPEC 中RPS</a></li>
</ul>

<p>HEVC 对于参考帧的管理会有专门的参数集 RPS(Reference Picture Set) 来进行管理。RPS 技术，通过直接在每一帧开始的片头码流中传输 DPB 中各个帧的状态变化。<br />
<!--more--></p>

<h2 id="hevc-spec-rps">HEVC SPEC 中RPS</h2>

<p>关于 RPS 部分的描述，SPEC 中在 7.4.8 中：<br />
<code>st_ref_pic_set(stRpsIdx)</code>语法结构可能存在<code>SPS</code>或<code>Slice Header</code>中，根据 RPS 语法结构是否存在 SPS 或 Slice Header 中，应用如下：</p>

<blockquote>
  <p>如果 RPS 存在 Slice Header 中，<code>st_ref_pic_set(stRpsIdx)</code>语法结构指定了当前图像的 short-term RPS：<br />
&gt; 当前图片的所有 slice header 中<code>st_ref_pic_set(stRpsIdx)</code>语法结构全部相同。<br />
&gt; stRpsIdx 的值应该与当前图像参考的 SPS 的 num_short_term_ref_pic_sets 相同。<br />
&gt; 
如果 RPS 存在在 SPS 中，</p>
</blockquote>

<p><img src="/images/rps/hevc_rps.png"></p>

<ul>
  <li>inter_ref_pic_set_prediction_flag 值为1</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC 学习之 Frame Rate]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/25/hevc-fps/"/>
    <updated>2016-11-25T00:13:47-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/25/hevc-fps</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#sps-frame-rate" id="markdown-toc-sps-frame-rate">SPS Frame Rate</a></li>
  <li><a href="#vps-frame-rate" id="markdown-toc-vps-frame-rate">VPS Frame Rate</a></li>
  <li><a href="#container-frame-rate" id="markdown-toc-container-frame-rate">Container Frame Rate</a></li>
  <li><a href="#pts-frame-rate" id="markdown-toc-pts-frame-rate">PTS Frame Rate</a></li>
</ul>

<p><code>Frame Rate</code>是显示器上显示图像的频率,单位是 Hz,它作为视频文件的一个重要参数，本文记录<code>HEVC</code>码流中它的计算方法。</p>

<!--more-->

<p>HEVC 中关于<code>Frame Rate</code>的计算可以包含五中：从<code>SPS</code>中获取、从<code>VPS</code>中获取、从视频文件的<code>Container</code>层获取、根据PTS获取、选择默认值。</p>

<h2 id="sps-frame-rate">SPS Frame Rate</h2>

<ul>
  <li>vui_parameters_present_flag 值为 1 表示该码流中<code>vui_parameters()</code>语法结构存在。否则，该码流中不存在 VUI 结构。</li>
  <li>vui_timing_info_present_flag 值为 1 表示该码流中<code>vui_num_units_in_tick</code>、<code>vui_time_scale</code>、<code>vui_poc_proportional_to_timing_flag</code>和<code>vui_hrd_parameters_present_flag</code>存在，否则这些语法元素不存在。</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">if(vui_timing_info_present_flag){</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">vui_num_units_in_tick</td>
      <td style="text-align: center">u(u32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vui_time_scale</td>
      <td style="text-align: center">u(32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vui_poc_proportional_to_timing_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<ul>
  <li>vui_num_units_in_tick 是运行在<code>time_scale Hz</code>的频率（相应地时钟跳变计数器加一，称作一个时钟跳变）下的时钟的时间单元的数量。<code>vui_num_units_in_tick</code>应该大于 0。
一个时钟跳变(单位是秒)，它等于<code>vui_num_units_in_tick</code>除以<code>vui_time_scale</code>的四分之一。例如，视频信号的采样率是 25Hz,<code>vui_time_scale</code>值为 27000000,<code>vui_num_units_in_tick</code>值为1080000,因此一个时钟跳变值为 0.04 秒。</li>
</ul>

<p>当 SPS 参考的 VPS 中有<code>vps_num_units_in_tick</code>存在时，<code>vui_num_units_in_tick</code>如果存在，就应该等于<code>vps_num_units_in_tick</code>,<code>vui_num_units_in_tick</code>如果不存在，被推断为<code>vps_num_units_in_tick</code>。</p>

<ul>
  <li>vui_time_scale 是一秒内时间单元的数量。例如，一个以 27MHz 的时钟测量时间的时间坐标系的<code>time_scale</code>为 27000000。<code>vui_time_scale</code>的值应该大于 0。</li>
</ul>

<p>当 SPS 参考的 VPS 中有<code>vps_time_scale</code>存在时，<code>vui_time_scale</code>如果存在，就应该等于<code>vps_time_scale</code>,<code>vui_time_scale</code>如果不存在，被推断为<code>vps_num_units_in_tick</code>。</p>

<p>通过 SPS 计算的 FPS 的值为<code>fps = sps-&gt;vui-&gt;time_scale/sps-&gt;vui_num_units_in_tick</code>。</p>

<h2 id="vps-frame-rate">VPS Frame Rate</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">if(vps_timing_info_present_flag){</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">vps_num_units_in_tick</td>
      <td style="text-align: center">u(32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vps_time_scale</td>
      <td style="text-align: center">u(32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vps_poc_proporitonal_to_timing_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p>vps_num_units_in_tick 是运行在<code>vps_time_scale Hz</code>的频率（相应地时钟跳变计数器加一，称作一个时钟跳变）下的时钟的时间单元的数量。<code>vps_num_units_in_tick</code>应该大于 0。
一个时钟跳变(单位是秒)，它等于<code>vps_num_units_in_tick</code>除以<code>vps_time_scale</code>的四分之一。例如，视频信号的采样率是 25Hz,<code>vps_time_scale</code>值为 27000000,<code>vps_num_units_in_tick</code>值为1080000,因此一个时钟跳变值为 0.04 秒。</p>
  </li>
  <li>
    <p>vps_time_scale 是一秒内时间单元的数量。例如，一个以 27MHz 的时钟测量时间的时间坐标系的<code>vps_time_scale</code>为 27000000。<code>vps_time_scale</code>的值应该大于 0。</p>
  </li>
</ul>

<p>通过 VPS 计算的 FPS 的值为<code>fps = vps-&gt;time_scale / vps-&gt;num_units_in_tick</code>。</p>

<h2 id="container-frame-rate">Container Frame Rate</h2>

<p>这种方法得到的<code>Frame Rate</code>，其实并不是通过解码器得到的，而是通过从 DMX 端通过分析<code>Container</code>得到的，此处不做分析。</p>

<h2 id="pts-frame-rate">PTS Frame Rate</h2>

<p>如果上面都没有<code>Frame Rate</code>的信息，就可以通过<code>PTS</code>来计算出<code>Frame Rate</code>。方法就是通过计算 PTS 的间隔，然后得出<code>Frame Rate</code>的值。</p>

<blockquote>
  <p>注意，对于<code>HEVC</code>中，如果是<code>Interlace</code>码流，<code>Frame Rate</code>需要减半。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC 学习之SEI——Recovery_Point]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/24/hevc-sei-recovery-point/"/>
    <updated>2016-11-24T18:05:50-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/24/hevc-sei-recovery-point</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#recovery-point-sei-" id="markdown-toc-recovery-point-sei-">Recovery point SEI 消息语法</a></li>
  <li><a href="#recovery-point-sei--1" id="markdown-toc-recovery-point-sei--1">Recovery point SEI 消息语义</a></li>
  <li><a href="#hm--recoverypoint" id="markdown-toc-hm--recoverypoint">HM 中的 Recovery_Point</a></li>
</ul>

<p>本文主要记录 HEVC 中的 Recovery_Point 这一类 SEI PayloadType 的介绍。<code>recovery point</code>与<code>H264</code>中<code>recovery point</code>的功能是相似的，主要作用是帮助解码器确认，在解码器凯斯随机
访问或解码器遇到序列中断的链接以后，解码过程生成能够合格显示的图像的时间。</p>

<!--more-->

<h2 id="recovery-point-sei-">Recovery point SEI 消息语法</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">recovery_point(payloadSize)</th>
      <th style="text-align: center">Descriptor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">recovery_poc_cnt</td>
      <td style="text-align: center">se(v)</td>
    </tr>
    <tr>
      <td style="text-align: center">exact_match_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">broken_link_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
  </tbody>
</table>

<h2 id="recovery-point-sei--1">Recovery point SEI 消息语义</h2>

<p>当解码过程从一个解码顺序中与<code>recovery point sei payloadType</code>关联的访问单元开始时，所有此<code>SEI</code>消息指明的输出
顺序中<code>recovery point</code>以后的解码图像都是内容正确或大致正确的(即显示时不会有明显的马赛克)。有<code>recovery point sei payloadType</code>关联
的图像之前的随机访问单元生成的解码图像在内容上不一定是正确的，直到指定的<code>recovery point</code>。从与<code>recovery point sei payloadType</code>的访问
单元开始的解码过程操作可以包含对解码图像缓冲区不存在的图像的引用。</p>

<ul>
  <li>
    <p>recovery_poc_cnt 指定输出顺序中解码图像的恢复点。如果存在图像A, 以解码顺序看它在当前图像(与当前的 SEI 消息关联的图像)的后面，并且
它的 POC 等于当前图像的 POC 加上<code>recovery_poc_cnt</code>的值，则图像A被认定为<code>recovery point picture</code>。否则，显示顺序中第一个 POC 大于当前
图像 POC 加上 <code>recovery_poc_cnt</code>值的图像被认定为<code>recovery point picture</code>。<code>recovery point</code>图像在解码顺序中不能再当前图像的前面。以显示
顺序来看，从<code>recovery point</code>图像之后的所有解码图像在内容上都是正确或基本正确的。<code>recovery_poc_cnt</code>的值应当在<code>-MaxPicOrderCntLsb / 2</code>和
<code>MaxPicOrderCntLsb / 2 - 1</code>的范围内。</p>
  </li>
  <li>
    <p>exact_match_flag 表示在与恢复点 SEI 消息关联的访问单元处开始的解码过程输出的特定恢复点之后的解码图像，是否应该是一个与 NAL 单元流中
的前一个 IDR 访问单元位置处开始的解码过程生成的图像精确匹配的图像。值为 0 表示不一定精确匹配，为 1 表示精确匹配。</p>
  </li>
</ul>

<p>当解码从恢复点 SEI 消息开始时，所有对不可获得的参考图像的引用应当推断为对只包含用内部宏块预测方式编码的宏块，样点值为 Y 等于 128, Cb 和 Cr 等于
128（中度灰）的图像的引用，目的是确定与<code>exact_match_flag</code>的取值的一致性。</p>

<ul>
  <li>broken_link_flag 表示在恢复点 SEI 消息处 NAL 单元流的链接是否出现中断。它的语义如下：
—— 如果<code>broken_link_flag</code>值为 1， 在前一个 IDR 访问单元位置处开始的解码过程生成的图像可能包含不希望的视觉假象，以致于在输出顺序中关联恢复点 SEI 消息的访问单元之后
的解码图像不可显示，直到指定的输出顺序中的恢复点。<br />
—— 如果<code>broken_link_flag</code>值为 0, 没有预示会出现潜在的视觉假象。</li>
</ul>

<h2 id="hm--recoverypoint">HM 中的 Recovery_Point</h2>

<p>HM 源码中只是对<code>Recovery_Point</code>这一 SEI 信息做了 parse，但并没有使用解析出来的信息，可以认为 HM 中是不支持 <code>recovery_point</code>的。 其中解析的源码如下：</p>

<p><figure class='code'><figcaption><span>recovery_point </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="n">Void</span> <span class="n">SEIReader</span><span class="o">::</span><span class="n">xParseSEIRecoveryPoint</span><span class="p">(</span><span class="n">SEIRecoveryPoint</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">sei</span><span class="p">,</span> <span class="n">UInt</span> <span class="n">payloadSize</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">ostream</span> <span class="o">*</span><span class="n">pDecodedMessageOutputStream</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="n">Int</span>  <span class="n">iCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">UInt</span> <span class="n">uiCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">output_sei_message_header</span><span class="p">(</span><span class="n">sei</span><span class="p">,</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">payloadSize</span><span class="p">);</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">sei_read_svlc</span><span class="p">(</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">iCode</span><span class="p">,</span>  <span class="err">“</span><span class="n">recovery_poc_cnt</span><span class="err">”</span> <span class="p">);</span>      <span class="n">sei</span><span class="p">.</span><span class="n">m_recoveryPocCnt</span>     <span class="o">=</span> <span class="n">iCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">sei_read_flag</span><span class="p">(</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">uiCode</span><span class="p">,</span> <span class="err">“</span><span class="n">exact_matching_flag</span><span class="err">”</span> <span class="p">);</span>   <span class="n">sei</span><span class="p">.</span><span class="n">m_exactMatchingFlag</span>  <span class="o">=</span> <span class="n">uiCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">sei_read_flag</span><span class="p">(</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">uiCode</span><span class="p">,</span> <span class="err">“</span><span class="n">broken_link_flag</span><span class="err">”</span> <span class="p">);</span>      <span class="n">sei</span><span class="p">.</span><span class="n">m_brokenLinkFlag</span>     <span class="o">=</span> <span class="n">uiCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">xParseByteAlign</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC学习之PAR、DAR、SAR]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/16/par-sar-dar-analyse/"/>
    <updated>2016-11-16T08:11:53-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/16/par-sar-dar-analyse</id>
    <content type="html"><![CDATA[<p><a href="https://en.wikipedia.org/wiki/Aspect_ratio_(image)">Aspect Ratio</a> 是图片的宽高比。<br />
<!--more--></p>

<p>主要有 3 种<code>aspect ratio</code>：PAR(Pixel Aspect Ratio)、DAR(Display Aspect Ratio)、SAR(Sample Aspect Ratio)。</p>

<p>PAR(Pixel Aspect Ratio): 像素纵横比；<br />
DAR(Display Aspect Ratio):显示纵横比；<br />
SAR(Sample Aspect Ratio):采样纵横比；</p>

<p>三者的关系为PAR x SAR = DAR 或者 PAR = DAR / SAR。</p>

<h2 id="sarsample-aspect-ration">SAR(Sample Aspect Ration)采样纵横比</h2>

<p>HEVC SPEC 中关于 SAR 语法元素的描述如下：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">vui_parameters(){</th>
      <th style="text-align: center">Descriptor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">aspect_ratio_info_present_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">if(aspect_ratio_info_present_flag){</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">aspect_ratio_idc</td>
      <td style="text-align: center">u(8)</td>
    </tr>
    <tr>
      <td style="text-align: center">if(aspect_ratio_idc == EXTENDED_SRA){</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">sar_width</td>
      <td style="text-align: center">u(16)</td>
    </tr>
    <tr>
      <td style="text-align: center">sar_height</td>
      <td style="text-align: center">u(16)</td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<p>上面提到的 SAR 语法元素的语义如下：</p>

<ul>
  <li>aspect_ratio_info_present_flag 值为 1，指定<code>aspect_ratio_idc</code>在码流中存在；否则该语法元素不存在。</li>
  <li>aspect_ratio_idc 指定亮度采样的<code>SAR</code>的值。下面的表格展示它的含义。当<code>aspect_ratio_idc</code>值为 255，表明<code>EXTENDED_SRA</code>时，<code>SAR</code>的值
等于<code>sar_width:sar_height</code>。当<code>aspect_ratio_idc</code>语法不存在时，该值可以被认为是 0。<code>aspect_ratio_idc</code>的范围是<code>17-254</code>时，未使用，并且不该出现在码流中，此时解码器可以指定为 0。</li>
  <li>sar_width 表示<code>SAR</code>的水平大小。</li>
  <li>sar_height 表示<code>SAR</code>的竖直大小。<br />
<code>sar_width</code>和<code>sar_height</code>等于0、或<code>aspect_ratio_idc</code>等于0时，SPEC 未定义它的行为。</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">asepct_ratio_idc</th>
      <th style="text-align: center">Sample aspect ratio</th>
      <th>Examples of use(informative)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">Unspecified</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1:1(“square”)</td>
      <td>7680x4320 16:9 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: center">12:11</td>
      <td>720x576 4:3 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: center">10:11</td>
      <td>720x480 4:3 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: center">16:11</td>
      <td>720x576 16:9 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td>…</td>
    </tr>
    <tr>
      <td style="text-align: center">16</td>
      <td style="text-align: center">2:1</td>
      <td>960x1080 16:9 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">17…254</td>
      <td style="text-align: center">Reserved</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">255</td>
      <td style="text-align: center">EXTENDED_SAR</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="parpixel-aspect-ratio">PAR(Pixel Aspect Ratio)</h2>

<p>PAR 示例如下：</p>

<p><img src="/images/PAR_DAR_SAR/220px-PAR-1to1.svg.png" title="‘1to1_PAR’" ></p>

<p><img src="/images/PAR_DAR_SAR/220px-PAR-2to1.svg.png" title="‘2to1_PAR’" ></p>

<h2 id="dardisplay-aspect-ratio">DAR(Display Aspect Ratio)</h2>

<p>DAR 示例如下：</p>

<p><img src="/images/PAR_DAR_SAR/Aspect_ratio_16_9_example3.jpg" title="‘16to9_DAR’" ></p>

<p><img src="/images/PAR_DAR_SAR/Aspect_ratio_4_3_example.jpg" title="‘4to3_DAR’" ></p>

<h2 id="section">参考资料</h2>
<ol>
  <li><a href="https://www.animemusicvideos.org/guides/avtech3/theory-videoaspectratios.html">Advanced Aspect Ratios - PAR, DAR and SAR</a></li>
  <li><a href="http://forum.mediacoderhq.com/viewtopic.php?f=17&amp;t=8197">Understanding Aspect Ratios (DAR and PAR)</a></li>
  <li><a href="https://bavc.org/blog/par-sar-and-dar-making-sense-standard-definition-sd-video-pixels">PAR, SAR, and DAR: Making Sense of Standard Definition (SD) video pixels</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
