<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类:hevc | 懒人李冰]]></title>
  <link href="http://lazybing.github.io/blog/categories/hevc/atom.xml" rel="self"/>
  <link href="http://lazybing.github.io/"/>
  <updated>2021-11-01T06:47:21-07:00</updated>
  <id>http://lazybing.github.io/</id>
  <author>
    <name><![CDATA[李冰]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OverView of HEVC Standard]]></title>
    <link href="http://lazybing.github.io/blog/2021/10/16/overview-of-hevc-stand/"/>
    <updated>2021-10-16T06:48:21-07:00</updated>
    <id>http://lazybing.github.io/blog/2021/10/16/overview-of-hevc-stand</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">介绍</a></li>
  <li><a href="#hevc-" id="markdown-toc-hevc-">HEVC 编码设计和功能亮点</a>    <ul>
      <li><a href="#a-" id="markdown-toc-a-">A. 视频编码层</a>        <ul>
          <li><a href="#coding-tree-units-and-coding-tree-blockctb-structure" id="markdown-toc-coding-tree-units-and-coding-tree-blockctb-structure">1) Coding tree units and coding tree block(CTB) structure</a></li>
          <li><a href="#coding-unitscus-and-coding-blockscbs" id="markdown-toc-coding-unitscus-and-coding-blockscbs">2）Coding units(CUs) and coding blocks(CBs)</a></li>
          <li><a href="#prediction-units-and-prediction-blockspbs" id="markdown-toc-prediction-units-and-prediction-blockspbs">3）Prediction units and prediction blocks(PBs)</a></li>
          <li><a href="#tus-and-transform-blocks" id="markdown-toc-tus-and-transform-blocks">4）TUs and transform blocks</a></li>
          <li><a href="#motion-vector-signaling" id="markdown-toc-motion-vector-signaling">5）Motion vector signaling</a></li>
          <li><a href="#motion-compensation" id="markdown-toc-motion-compensation">6）Motion compensation</a></li>
          <li><a href="#intrapicture-prediction" id="markdown-toc-intrapicture-prediction">7) Intrapicture prediction</a></li>
          <li><a href="#quantization-control" id="markdown-toc-quantization-control">8) Quantization control</a></li>
          <li><a href="#entropy-coding" id="markdown-toc-entropy-coding">9）Entropy coding</a></li>
          <li><a href="#in-loop-deblocking-filtering" id="markdown-toc-in-loop-deblocking-filtering">10）In-loop deblocking filtering</a></li>
          <li><a href="#sample-adaptive-offsetsao" id="markdown-toc-sample-adaptive-offsetsao">11）Sample adaptive offset(SAO)</a></li>
        </ul>
      </li>
      <li><a href="#b-" id="markdown-toc-b-">B. 高级语法体系结构</a>        <ul>
          <li><a href="#parameter-set-structure" id="markdown-toc-parameter-set-structure">1）Parameter set structure</a></li>
          <li><a href="#nal-unit-syntax-structure" id="markdown-toc-nal-unit-syntax-structure">2）NAL unit syntax structure</a></li>
          <li><a href="#slices" id="markdown-toc-slices">3）Slices</a></li>
          <li><a href="#sei--vui" id="markdown-toc-sei--vui">4）SEI 和 VUI</a></li>
        </ul>
      </li>
      <li><a href="#c--slice-" id="markdown-toc-c--slice-">C. 并行解码语法与改进的 slice 结构</a>        <ul>
          <li><a href="#section-1" id="markdown-toc-section-1">1）</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>HEVC 是 ITU-T 视频编码专家组和 ISO/IEC 运动图像专家组的最新视频编码标准。HEVC 标准化工作的主要目标是相对于现有标准，在 50% 的比特率降低范围内显著提高压缩性能，以获得相同的感知视频质量。本文概述了 HEVC 标准的技术特性和特点。</p>

<!--more-->

<h2 id="section">介绍</h2>

<p>HEVC 标准是 ITU-T 视频编码专家组(VCEG)和 ISO/IEC 运动图像专家组(MPEG)标准化组织的最新联合视频项目，它们在一个称为视频编码联合协助小组(JCT-VC)的伙伴组织关系中共同工作。HEVC 标准的第一版预计将于 2013 年 1 月定稿，最终形成一份由 ITU-T 和 ISO/IEC 共同发布的统一文本。后续会有更多工作，以扩展该标准，从而支持多个其他应用场景，包括具有增强精度和颜色格式支持的扩展范围使用、可伸缩视频编码和三维/立体/多视图视频编码。在 ISO/IEC 中，HEVC标准将成为 MPEG-H 第 2 部分(ISO/IEC 23008-2)，在 ITU-T 中，它很可能成为 ITU-T 建议 H.265。</p>

<p>视频编码标准主要通过注明的 ITU-T 和 ISO/IEC 标准的发展而起来的。ITU-T 生产了 H.261 和 H.263，ISO/IEC 生产了 MPEG-1 和 MPEG-4视频，这两个组织联合生产了 H.262/MPEG-2视频和 H.264/MPEG-4 AVC 标准。这两项联合制定的标准产生了特别强烈的影响，并已被广泛应用于我们日常生活中日益流行的各种产品中。在这一演变过程中，不断努力最大限度地提高压缩能力，并改进其他特性，如数据丢失鲁棒性，同时考虑到在预期部署每个标准时，产品中实际使用的计算资源。</p>

<p>HEVC 之前的主要视频编码标准是 H.264/MPEG-4 AVC，它最初是在 1999 年至 2003 年期间开发的，然后在 2003 年至 2009 年期间以几种重要方式进行了扩展。H.264/MPEG-4 AVC 是数字视频的一种使能技术，几乎涵盖了 H.262/MPEG-2 视频之前未涵盖的所有领域，并在其现有应用领域中基本上取代了旧标准。它广泛应用于许多应用，包括通过卫星、有线和地面传输系统广播高清(HD)电视信号、视频内容采集和编辑系统、摄像机、安全应用、互联网和移动网络视频、蓝光光盘以及视频聊天等实时对话应用，视频会议和远程呈现系统。</p>

<p>然而，服务的日益多样化、高清视频的日益普及以及超高清格式(如4kx2k 或 8kx4k分辨率)的出现，对编码效率的需求甚至超出了 H.264/MPEG-4 AVC 的能力。当更高的分辨率伴随立体声或多视图捕获和显示时，这种需求更强烈了。此外，针对移动设备和平板电脑的视频应用程序所带来的流量，以及视频点播服务的传输需求，正在给当今的网络带来严峻挑战。在移动应用程序中，对更高质量和分辨率的需求也越来越强烈。</p>

<p>HEVC 旨在解决 H.264/AVC 的所有现有应用，并特别关注两个特别问题：提高视频分辨率，增加并行处理框架的使用。HEVC 的语法是通用的，通常也适用于上面没有特别提到的其他应用程序。</p>

<p>与过去所有的 ITU-T 和 ISO/IEC 视频编码标准一样，在 HEVC 中，只有比特流结构和语法是标准化的，并且对生产解码图片的比特流及其映射的约束也是标准化的。通过定义语法元素的语义和解码过程来给出映射，使得当给定符合标准约束的比特流时，符合标准的每个解码器将产生相同的输出。标准范围的这种限制允许以适合特定应用的方式(平衡压缩质量、实现成本、上市时间和其他考虑因素)最大限度地优化实现。然而，它并不能保证端到端的复制质量，因为它甚至允许有损失的编码技术被认为是合格的。</p>

<p>为了帮助行业社区学习如何使用标准，标准化工作不仅包括开发文本规范文档，还包括参考软件源代码，作为如何编码和解码 HEVC 视频的示例。在标准设计期间，参考软件草案已被用作委员会内部工作的研究工具，也可作为通用研究工具和产品基础，还正在开发标准测试数据套件，以测试是否符合该标准。</p>

<p>本文的组织结构如下：第二部分重点介绍 HEVC 编码设计的一些关键特性。第三部分解释了 HEVC 编码数据的高级语法和总体结构。第四部分将更详细地描述 HEVC 编码技术。第五部分解释了 HEVC 的 profile、tier 和 level 设计。由于编写像  HEVC 这样实质性的技术概述需要大量的总结，如有遗漏，请向读者咨询。第六部分讨论了 HEVC 标准化工作的历史。</p>

<h2 id="hevc-">HEVC 编码设计和功能亮点</h2>

<p>HEVC 标准旨在实现多个目标，包括编码效率、易于传输系统集成和数据丢失恢复能力，以及使用并行处理架构的可实现性。下面小节简要描述了实现这些目标的设计关键要素，以及生成有效比特流的典型编码器操作。第三节和第四节提供了有关不同元素的相关语法和解码过程的更多细节。</p>

<h3 id="a-">A. 视频编码层</h3>

<p>HEVC 的视频编码层采用自 H.261 以来所有视频压缩标准中使用的相同的混合编码方法(图像间/图像内预测和二维变换编码)。图 1 描述了可创建符合 HEVC 标准的比特流的混合视频编码器的框图。</p>

<p>产生符合 HEVC 的比特流的编码算法通常如下进行：每个图片被分割成块形区域，精确的块分割被传送到解码器。视频序列的第一幅图片(以及每个随机接入点处的第一幅图片到视频序列中)仅使用图片内预测进行编码(该预测使用同一图片内从区域到区域的空间数据预测，但不依赖于其他图片)。对于序列或随机接入点间的所有剩余图片，通常对大多数块使用图像间时间预测编码模式。用于画面间预测的编码处理包括：选择包含所选参考画面和运动矢量(MV)的运动数据，以应用于预测每个块的样本。编码器和解码器通过使用 MV 和模式决策数据应用运动补偿(MC)来生成相同的图像间预测信号，这些数据作为边信息传输。</p>

<p>帧内或帧间预测的残余信号(即原始块与其预测之间的差值)，通过线性空间变换进行变换。然后对变换系数进行缩放、量化、熵编码，并与预测信心一起传输。</p>

<p>编码器复制解码器处理循环(参见图1中的灰色阴影框)，以便两者将为后续数据生成相同的预测。因此，量化变换系数通过逆缩放构造，然后逆变换以复制剩余信号的解码近似。然后将残差添加到预测中，并且该添加的结果随后可被反馈到一个或两个环路滤波器中以平滑由分块处理和量化引起的伪影。最终图片表示(即解码器输出的副本)存储在解码图片缓冲器中，以用于后续图片的预测。一般来说，图片的编码或解码处理顺序通常不同于它们从源到达的顺序，需要区分解码器的解码顺序(即比特流顺序)和输出顺序(即显示顺序)。</p>

<p>要由 HEVC 编码的视频材料通常应作为逐行扫描图像输入(由于源视频以该格式产生，或由编码前去交错)。HEVC 设计中不存在明确的编码特征，以支持隔行扫描的使用，因为隔行扫描不再用于显示，并且在分发中变得越来越步常见。然而，在 HEVC 中提供了元数据语法，以允许编码器通过将隔行扫描视频的每个字段(即，每个视频帧的偶数或奇数行)编码以单独图片来指示隔行扫描视频已被发送，或这其已通过将每个隔行扫描帧编码为 HEVC 编码图片来发送。这提供了一种对隔行视频进行编码的有效方法，而无需使解码器负担对其支持特殊解码过程的负担。</p>

<p>在下文中，使用 HEVC 的混合视频编码所涉及的各种特性如下所示。</p>

<h4 id="coding-tree-units-and-coding-tree-blockctb-structure">1) Coding tree units and coding tree block(CTB) structure</h4>

<p>在以前的标准中，编码层的核心是宏块，它包含 luma 采样的 16x16 宏块，在通常的 4:2:0 颜色采样情况下，chroma 采样有对应的 8x8 色度块；而 HEVC 中的类似结构是编码树单元(CTU)，其大小由编码器选择，可以大于传统宏块。CTU 由 luma CTB 和对应的色度 CTB 以及语法元素组成。luma CTB 的大小可以选择为 L=16、32或64个样本，较大的大小通常能够实现更好的压缩。HEVC 支持使用树结构和类似四叉树的信令将 CTB 划分为更小的块。</p>

<h4 id="coding-unitscus-and-coding-blockscbs">2）Coding units(CUs) and coding blocks(CBs)</h4>

<p>CTU 的四叉树语法指定其亮度和色度 CBs 的大小和位置。四叉树的根与 CTU 关联。因此，luma CTB 的大小是 luma CB 支持的最大大小。CTU 分为 luma 和 chroma CBs 是联合发出的信号。一个 luma CB 和两个 sample CB，连同相关的语法，构成一个编码单元(CU)。一个 CTB 可以只包含一个 CU，或者可以分割成多个 CU，并且每个 CU 都有一个相关的分区为预测单元(PU)和变换单元树(TU)。</p>

<h4 id="prediction-units-and-prediction-blockspbs">3）Prediction units and prediction blocks(PBs)</h4>

<p>在 CU 级别决定是使用图像间预测还是图像内预测对图片区域进行编码。PU 分区结构的根位于 CU 级别。取决于基本预测类型决策，luma 和 chroma CBs 随后可以在大小上进一步分割并从 luma 和 chroma 预测块(PBs)预测。HEVC 支持从 64x64 到 4x4 样本的可变 PB 大小。</p>

<h4 id="tus-and-transform-blocks">4）TUs and transform blocks</h4>

<p>使用块变换对预测残差进行编码。TU 树结构的根位于 CU 级别。luma CB 残差可以与 luma 变换块(TB)相同，或者可以进一步分割成更小的 luma TB。这同样适用于 chroma TBs。对于 4x4、8x8、16x16 和 32x32 的正方形 TB，定义了与DCT 类似的整数基函数。对于 luma 图像内预测残差的 4x4 变换，可选指定从 DST 形式导出的整数变换。</p>

<h4 id="motion-vector-signaling">5）Motion vector signaling</h4>

<p>使用AMVP(Advanced motion vector prediction)，包括基于来自相邻 PBs 和参考图片的数据导出几个最可能的候选。还使用 MV 编码的合并模式，允许 MV 从时间上或空间上相邻的 PBs 继承。此外，与 H.264/AVC 相比，还指定了改进的 skipped 和 直接运动推断。</p>

<h4 id="motion-compensation">6）Motion compensation</h4>

<p>MVs 使用四分之一采样精度，分数采样位置的插值使用 7 抽头或 8 抽头滤波器(相比之下，H.264/AVC 中，半采样位置的六抽头滤波后，四分之一采样位置的线性插值)。与 H.264/AVC 类似，使用了多个参考图片。对于每个 PB，传输一个或两个运动矢量，分别表示单预测或双预测编码。如在 H.264/AVC 中一样，可以称为加权预测的方式对预测信号应用缩放和偏移操作。</p>

<h4 id="intrapicture-prediction">7) Intrapicture prediction</h4>

<p>相邻块的间边界样本，用作未执行帧间预测的区域中的空间预测的参考数据。图像内预测支持 33 种方向模式(与 H.264/AVC 中的 8 种模式相比)，以及plus plannr 和 DC 预测模式。通过基于先前解码的相邻 PBs 的模式导出最可能模式(例如，预测方向)来编码所选择的画面内预测模式。</p>

<h4 id="quantization-control">8) Quantization control</h4>

<p>与 H.264/AVC 中一样，HEVC 中使用均匀重建量化(URQ)，量化缩放矩阵支持各种变换块大小。</p>

<h4 id="entropy-coding">9）Entropy coding</h4>

<p>CABAC 用于熵编码。这类似于 H.264/AVC 中的 CABAC 方案，单经过几次改进以提高其吞吐量速度(特别是对于并行处理架构)和压缩性能，并降低其上下文内存需求。</p>

<h4 id="in-loop-deblocking-filtering">10）In-loop deblocking filtering</h4>

<p>与 H.264/AVC 中使用的去块滤波器类似去块滤波器，在图像间预测循环中操作。然而，该设计在决策和过滤过程方面得到了简化，并且对并行处理更加友好。</p>

<h4 id="sample-adaptive-offsetsao">11）Sample adaptive offset(SAO)</h4>

<p>在去块滤波器之后，在图像间预测环路中引入非线性振幅映射。它的目标是通过使用查找表更好地重建原始信号振幅，该查找表由几个附加参数描述，这些参数可以通过编码器端的直方图分析确定。</p>

<h3 id="b-">B. 高级语法体系结构</h3>

<p>HEVC 标准新增的许多设计方面，提高了在各种应用程序和网络环境下操作的灵活性，并提高了数据丢失的鲁棒性。然而，H.264/AVC 标准中使用的高级语法体系结构通常被保留，包括以下特征。</p>

<h4 id="parameter-set-structure">1）Parameter set structure</h4>

<p>参数集包含可共享的信息，用于解码解码视频的多个区域。参数集结构提供了用于传输解码过程所必需的数据的健壮机制。通过一种新的 VPS 结构，对 H.264/AVC 中的序列和图片参数集的概念进行了扩充。</p>

<h4 id="nal-unit-syntax-structure">2）NAL unit syntax structure</h4>

<p>每个语法结构都被放入 NAL 单元的逻辑数据包中。使用两个字节 NAL 单元报头的内容，可以容易地识别相关有效负载数据的用途。</p>

<h4 id="slices">3）Slices</h4>

<p>slice 是一种数据结构，在熵编码、信号预测和残差信号重建方面，可以独立于同一图片的其他 slice 进行解码。slice 可以是整个图片，也可以是图片中的一个区域。slice 的主要用途之一是在数据丢失时重新同步。在分组传输的情况下， slice 内有效负载比特的最大数量通常受到限制，并且 slice 中 CTU 的数量经常变化以最小化分组开销，同时将每个分组的大小保持在此范围内。</p>

<h4 id="sei--vui">4）SEI 和 VUI</h4>

<p>该语法元素支持各种类型元数据，比如 SEI 和 VUI。这些数据提供关于视频图片的定时、视频信号中使用的颜色空间的正确解释、三维立体帧打包信息、其他显示提示信息等的信息。</p>

<h3 id="c--slice-">C. 并行解码语法与改进的 slice 结构</h3>

<p>最后，HEVC 标准中引入了四个新的特性，以增强并行处理能力或修改 slice 数据的结构以实现打包。它们中的每一个在特定的应用环境中都可能有好处，并且通常由编码器或解码器的实现者来确定是否以及如何利用这些特性。</p>

<h4 id="section-1">1）</h4>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC学习之RPS(待整理)]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/27/hevc-rps/"/>
    <updated>2016-11-27T06:20:37-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/27/hevc-rps</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#hevc-spec-rps" id="markdown-toc-hevc-spec-rps">HEVC SPEC 中RPS</a></li>
</ul>

<p>HEVC 对于参考帧的管理会有专门的参数集 RPS(Reference Picture Set) 来进行管理。RPS 技术，通过直接在每一帧开始的片头码流中传输 DPB 中各个帧的状态变化。<br />
<!--more--></p>

<h2 id="hevc-spec-rps">HEVC SPEC 中RPS</h2>

<p>关于 RPS 部分的描述，SPEC 中在 7.4.8 中：<br />
<code>st_ref_pic_set(stRpsIdx)</code>语法结构可能存在<code>SPS</code>或<code>Slice Header</code>中，根据 RPS 语法结构是否存在 SPS 或 Slice Header 中，应用如下：</p>

<blockquote>
  <p>如果 RPS 存在 Slice Header 中，<code>st_ref_pic_set(stRpsIdx)</code>语法结构指定了当前图像的 short-term RPS：<br />
&gt; 当前图片的所有 slice header 中<code>st_ref_pic_set(stRpsIdx)</code>语法结构全部相同。<br />
&gt; stRpsIdx 的值应该与当前图像参考的 SPS 的 num_short_term_ref_pic_sets 相同。<br />
&gt; 
如果 RPS 存在在 SPS 中，</p>
</blockquote>

<p><img src="/images/rps/hevc_rps.png"></p>

<ul>
  <li>inter_ref_pic_set_prediction_flag 值为1</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC 学习之 Frame Rate]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/25/hevc-fps/"/>
    <updated>2016-11-25T00:13:47-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/25/hevc-fps</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#sps-frame-rate" id="markdown-toc-sps-frame-rate">SPS Frame Rate</a></li>
  <li><a href="#vps-frame-rate" id="markdown-toc-vps-frame-rate">VPS Frame Rate</a></li>
  <li><a href="#container-frame-rate" id="markdown-toc-container-frame-rate">Container Frame Rate</a></li>
  <li><a href="#pts-frame-rate" id="markdown-toc-pts-frame-rate">PTS Frame Rate</a></li>
</ul>

<p><code>Frame Rate</code>是显示器上显示图像的频率,单位是 Hz,它作为视频文件的一个重要参数，本文记录<code>HEVC</code>码流中它的计算方法。</p>

<!--more-->

<p>HEVC 中关于<code>Frame Rate</code>的计算可以包含五中：从<code>SPS</code>中获取、从<code>VPS</code>中获取、从视频文件的<code>Container</code>层获取、根据PTS获取、选择默认值。</p>

<h2 id="sps-frame-rate">SPS Frame Rate</h2>

<ul>
  <li>vui_parameters_present_flag 值为 1 表示该码流中<code>vui_parameters()</code>语法结构存在。否则，该码流中不存在 VUI 结构。</li>
  <li>vui_timing_info_present_flag 值为 1 表示该码流中<code>vui_num_units_in_tick</code>、<code>vui_time_scale</code>、<code>vui_poc_proportional_to_timing_flag</code>和<code>vui_hrd_parameters_present_flag</code>存在，否则这些语法元素不存在。</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">if(vui_timing_info_present_flag){</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">vui_num_units_in_tick</td>
      <td style="text-align: center">u(u32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vui_time_scale</td>
      <td style="text-align: center">u(32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vui_poc_proportional_to_timing_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<ul>
  <li>vui_num_units_in_tick 是运行在<code>time_scale Hz</code>的频率（相应地时钟跳变计数器加一，称作一个时钟跳变）下的时钟的时间单元的数量。<code>vui_num_units_in_tick</code>应该大于 0。
一个时钟跳变(单位是秒)，它等于<code>vui_num_units_in_tick</code>除以<code>vui_time_scale</code>的四分之一。例如，视频信号的采样率是 25Hz,<code>vui_time_scale</code>值为 27000000,<code>vui_num_units_in_tick</code>值为1080000,因此一个时钟跳变值为 0.04 秒。</li>
</ul>

<p>当 SPS 参考的 VPS 中有<code>vps_num_units_in_tick</code>存在时，<code>vui_num_units_in_tick</code>如果存在，就应该等于<code>vps_num_units_in_tick</code>,<code>vui_num_units_in_tick</code>如果不存在，被推断为<code>vps_num_units_in_tick</code>。</p>

<ul>
  <li>vui_time_scale 是一秒内时间单元的数量。例如，一个以 27MHz 的时钟测量时间的时间坐标系的<code>time_scale</code>为 27000000。<code>vui_time_scale</code>的值应该大于 0。</li>
</ul>

<p>当 SPS 参考的 VPS 中有<code>vps_time_scale</code>存在时，<code>vui_time_scale</code>如果存在，就应该等于<code>vps_time_scale</code>,<code>vui_time_scale</code>如果不存在，被推断为<code>vps_num_units_in_tick</code>。</p>

<p>通过 SPS 计算的 FPS 的值为<code>fps = sps-&gt;vui-&gt;time_scale/sps-&gt;vui_num_units_in_tick</code>。</p>

<h2 id="vps-frame-rate">VPS Frame Rate</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">if(vps_timing_info_present_flag){</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">vps_num_units_in_tick</td>
      <td style="text-align: center">u(32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vps_time_scale</td>
      <td style="text-align: center">u(32)</td>
    </tr>
    <tr>
      <td style="text-align: center">vps_poc_proporitonal_to_timing_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p>vps_num_units_in_tick 是运行在<code>vps_time_scale Hz</code>的频率（相应地时钟跳变计数器加一，称作一个时钟跳变）下的时钟的时间单元的数量。<code>vps_num_units_in_tick</code>应该大于 0。
一个时钟跳变(单位是秒)，它等于<code>vps_num_units_in_tick</code>除以<code>vps_time_scale</code>的四分之一。例如，视频信号的采样率是 25Hz,<code>vps_time_scale</code>值为 27000000,<code>vps_num_units_in_tick</code>值为1080000,因此一个时钟跳变值为 0.04 秒。</p>
  </li>
  <li>
    <p>vps_time_scale 是一秒内时间单元的数量。例如，一个以 27MHz 的时钟测量时间的时间坐标系的<code>vps_time_scale</code>为 27000000。<code>vps_time_scale</code>的值应该大于 0。</p>
  </li>
</ul>

<p>通过 VPS 计算的 FPS 的值为<code>fps = vps-&gt;time_scale / vps-&gt;num_units_in_tick</code>。</p>

<h2 id="container-frame-rate">Container Frame Rate</h2>

<p>这种方法得到的<code>Frame Rate</code>，其实并不是通过解码器得到的，而是通过从 DMX 端通过分析<code>Container</code>得到的，此处不做分析。</p>

<h2 id="pts-frame-rate">PTS Frame Rate</h2>

<p>如果上面都没有<code>Frame Rate</code>的信息，就可以通过<code>PTS</code>来计算出<code>Frame Rate</code>。方法就是通过计算 PTS 的间隔，然后得出<code>Frame Rate</code>的值。</p>

<blockquote>
  <p>注意，对于<code>HEVC</code>中，如果是<code>Interlace</code>码流，<code>Frame Rate</code>需要减半。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC 学习之SEI——Recovery_Point]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/24/hevc-sei-recovery-point/"/>
    <updated>2016-11-24T18:05:50-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/24/hevc-sei-recovery-point</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#recovery-point-sei-" id="markdown-toc-recovery-point-sei-">Recovery point SEI 消息语法</a></li>
  <li><a href="#recovery-point-sei--1" id="markdown-toc-recovery-point-sei--1">Recovery point SEI 消息语义</a></li>
  <li><a href="#hm--recoverypoint" id="markdown-toc-hm--recoverypoint">HM 中的 Recovery_Point</a></li>
</ul>

<p>本文主要记录 HEVC 中的 Recovery_Point 这一类 SEI PayloadType 的介绍。<code>recovery point</code>与<code>H264</code>中<code>recovery point</code>的功能是相似的，主要作用是帮助解码器确认，在解码器凯斯随机
访问或解码器遇到序列中断的链接以后，解码过程生成能够合格显示的图像的时间。</p>

<!--more-->

<h2 id="recovery-point-sei-">Recovery point SEI 消息语法</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">recovery_point(payloadSize)</th>
      <th style="text-align: center">Descriptor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">recovery_poc_cnt</td>
      <td style="text-align: center">se(v)</td>
    </tr>
    <tr>
      <td style="text-align: center">exact_match_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">broken_link_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
  </tbody>
</table>

<h2 id="recovery-point-sei--1">Recovery point SEI 消息语义</h2>

<p>当解码过程从一个解码顺序中与<code>recovery point sei payloadType</code>关联的访问单元开始时，所有此<code>SEI</code>消息指明的输出
顺序中<code>recovery point</code>以后的解码图像都是内容正确或大致正确的(即显示时不会有明显的马赛克)。有<code>recovery point sei payloadType</code>关联
的图像之前的随机访问单元生成的解码图像在内容上不一定是正确的，直到指定的<code>recovery point</code>。从与<code>recovery point sei payloadType</code>的访问
单元开始的解码过程操作可以包含对解码图像缓冲区不存在的图像的引用。</p>

<ul>
  <li>
    <p>recovery_poc_cnt 指定输出顺序中解码图像的恢复点。如果存在图像A, 以解码顺序看它在当前图像(与当前的 SEI 消息关联的图像)的后面，并且
它的 POC 等于当前图像的 POC 加上<code>recovery_poc_cnt</code>的值，则图像A被认定为<code>recovery point picture</code>。否则，显示顺序中第一个 POC 大于当前
图像 POC 加上 <code>recovery_poc_cnt</code>值的图像被认定为<code>recovery point picture</code>。<code>recovery point</code>图像在解码顺序中不能再当前图像的前面。以显示
顺序来看，从<code>recovery point</code>图像之后的所有解码图像在内容上都是正确或基本正确的。<code>recovery_poc_cnt</code>的值应当在<code>-MaxPicOrderCntLsb / 2</code>和
<code>MaxPicOrderCntLsb / 2 - 1</code>的范围内。</p>
  </li>
  <li>
    <p>exact_match_flag 表示在与恢复点 SEI 消息关联的访问单元处开始的解码过程输出的特定恢复点之后的解码图像，是否应该是一个与 NAL 单元流中
的前一个 IDR 访问单元位置处开始的解码过程生成的图像精确匹配的图像。值为 0 表示不一定精确匹配，为 1 表示精确匹配。</p>
  </li>
</ul>

<p>当解码从恢复点 SEI 消息开始时，所有对不可获得的参考图像的引用应当推断为对只包含用内部宏块预测方式编码的宏块，样点值为 Y 等于 128, Cb 和 Cr 等于
128（中度灰）的图像的引用，目的是确定与<code>exact_match_flag</code>的取值的一致性。</p>

<ul>
  <li>broken_link_flag 表示在恢复点 SEI 消息处 NAL 单元流的链接是否出现中断。它的语义如下：
—— 如果<code>broken_link_flag</code>值为 1， 在前一个 IDR 访问单元位置处开始的解码过程生成的图像可能包含不希望的视觉假象，以致于在输出顺序中关联恢复点 SEI 消息的访问单元之后
的解码图像不可显示，直到指定的输出顺序中的恢复点。<br />
—— 如果<code>broken_link_flag</code>值为 0, 没有预示会出现潜在的视觉假象。</li>
</ul>

<h2 id="hm--recoverypoint">HM 中的 Recovery_Point</h2>

<p>HM 源码中只是对<code>Recovery_Point</code>这一 SEI 信息做了 parse，但并没有使用解析出来的信息，可以认为 HM 中是不支持 <code>recovery_point</code>的。 其中解析的源码如下：</p>

<p><figure class='code'><figcaption><span>recovery_point </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="n">Void</span> <span class="n">SEIReader</span><span class="o">::</span><span class="n">xParseSEIRecoveryPoint</span><span class="p">(</span><span class="n">SEIRecoveryPoint</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">sei</span><span class="p">,</span> <span class="n">UInt</span> <span class="n">payloadSize</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">ostream</span> <span class="o">*</span><span class="n">pDecodedMessageOutputStream</span><span class="p">)</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="n">Int</span>  <span class="n">iCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">UInt</span> <span class="n">uiCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">output_sei_message_header</span><span class="p">(</span><span class="n">sei</span><span class="p">,</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">payloadSize</span><span class="p">);</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">sei_read_svlc</span><span class="p">(</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">iCode</span><span class="p">,</span>  <span class="err">“</span><span class="n">recovery_poc_cnt</span><span class="err">”</span> <span class="p">);</span>      <span class="n">sei</span><span class="p">.</span><span class="n">m_recoveryPocCnt</span>     <span class="o">=</span> <span class="n">iCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">sei_read_flag</span><span class="p">(</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">uiCode</span><span class="p">,</span> <span class="err">“</span><span class="n">exact_matching_flag</span><span class="err">”</span> <span class="p">);</span>   <span class="n">sei</span><span class="p">.</span><span class="n">m_exactMatchingFlag</span>  <span class="o">=</span> <span class="n">uiCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">sei_read_flag</span><span class="p">(</span> <span class="n">pDecodedMessageOutputStream</span><span class="p">,</span> <span class="n">uiCode</span><span class="p">,</span> <span class="err">“</span><span class="n">broken_link_flag</span><span class="err">”</span> <span class="p">);</span>      <span class="n">sei</span><span class="p">.</span><span class="n">m_brokenLinkFlag</span>     <span class="o">=</span> <span class="n">uiCode</span><span class="p">;</span>
</span><span class='line'>  <span class="n">xParseByteAlign</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HEVC SPEC学习之PAR、DAR、SAR]]></title>
    <link href="http://lazybing.github.io/blog/2016/11/16/par-sar-dar-analyse/"/>
    <updated>2016-11-16T08:11:53-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/11/16/par-sar-dar-analyse</id>
    <content type="html"><![CDATA[<p><a href="https://en.wikipedia.org/wiki/Aspect_ratio_(image)">Aspect Ratio</a> 是图片的宽高比。<br />
<!--more--></p>

<p>主要有 3 种<code>aspect ratio</code>：PAR(Pixel Aspect Ratio)、DAR(Display Aspect Ratio)、SAR(Sample Aspect Ratio)。</p>

<p>PAR(Pixel Aspect Ratio): 像素纵横比；<br />
DAR(Display Aspect Ratio):显示纵横比；<br />
SAR(Sample Aspect Ratio):采样纵横比；</p>

<p>三者的关系为PAR x SAR = DAR 或者 PAR = DAR / SAR。</p>

<h2 id="sarsample-aspect-ration">SAR(Sample Aspect Ration)采样纵横比</h2>

<p>HEVC SPEC 中关于 SAR 语法元素的描述如下：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">vui_parameters(){</th>
      <th style="text-align: center">Descriptor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">aspect_ratio_info_present_flag</td>
      <td style="text-align: center">u(1)</td>
    </tr>
    <tr>
      <td style="text-align: center">if(aspect_ratio_info_present_flag){</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">aspect_ratio_idc</td>
      <td style="text-align: center">u(8)</td>
    </tr>
    <tr>
      <td style="text-align: center">if(aspect_ratio_idc == EXTENDED_SRA){</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">sar_width</td>
      <td style="text-align: center">u(16)</td>
    </tr>
    <tr>
      <td style="text-align: center">sar_height</td>
      <td style="text-align: center">u(16)</td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">}</td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<p>上面提到的 SAR 语法元素的语义如下：</p>

<ul>
  <li>aspect_ratio_info_present_flag 值为 1，指定<code>aspect_ratio_idc</code>在码流中存在；否则该语法元素不存在。</li>
  <li>aspect_ratio_idc 指定亮度采样的<code>SAR</code>的值。下面的表格展示它的含义。当<code>aspect_ratio_idc</code>值为 255，表明<code>EXTENDED_SRA</code>时，<code>SAR</code>的值
等于<code>sar_width:sar_height</code>。当<code>aspect_ratio_idc</code>语法不存在时，该值可以被认为是 0。<code>aspect_ratio_idc</code>的范围是<code>17-254</code>时，未使用，并且不该出现在码流中，此时解码器可以指定为 0。</li>
  <li>sar_width 表示<code>SAR</code>的水平大小。</li>
  <li>sar_height 表示<code>SAR</code>的竖直大小。<br />
<code>sar_width</code>和<code>sar_height</code>等于0、或<code>aspect_ratio_idc</code>等于0时，SPEC 未定义它的行为。</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">asepct_ratio_idc</th>
      <th style="text-align: center">Sample aspect ratio</th>
      <th>Examples of use(informative)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">Unspecified</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1:1(“square”)</td>
      <td>7680x4320 16:9 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: center">12:11</td>
      <td>720x576 4:3 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: center">10:11</td>
      <td>720x480 4:3 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: center">16:11</td>
      <td>720x576 16:9 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">…</td>
      <td style="text-align: center">…</td>
      <td>…</td>
    </tr>
    <tr>
      <td style="text-align: center">16</td>
      <td style="text-align: center">2:1</td>
      <td>960x1080 16:9 frame without horizontal overscan</td>
    </tr>
    <tr>
      <td style="text-align: center">17…254</td>
      <td style="text-align: center">Reserved</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">255</td>
      <td style="text-align: center">EXTENDED_SAR</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="parpixel-aspect-ratio">PAR(Pixel Aspect Ratio)</h2>

<p>PAR 示例如下：</p>

<p><img src="/images/PAR_DAR_SAR/220px-PAR-1to1.svg.png" title="‘1to1_PAR’" ></p>

<p><img src="/images/PAR_DAR_SAR/220px-PAR-2to1.svg.png" title="‘2to1_PAR’" ></p>

<h2 id="dardisplay-aspect-ratio">DAR(Display Aspect Ratio)</h2>

<p>DAR 示例如下：</p>

<p><img src="/images/PAR_DAR_SAR/Aspect_ratio_16_9_example3.jpg" title="‘16to9_DAR’" ></p>

<p><img src="/images/PAR_DAR_SAR/Aspect_ratio_4_3_example.jpg" title="‘4to3_DAR’" ></p>

<h2 id="section">参考资料</h2>
<ol>
  <li><a href="https://www.animemusicvideos.org/guides/avtech3/theory-videoaspectratios.html">Advanced Aspect Ratios - PAR, DAR and SAR</a></li>
  <li><a href="http://forum.mediacoderhq.com/viewtopic.php?f=17&amp;t=8197">Understanding Aspect Ratios (DAR and PAR)</a></li>
  <li><a href="https://bavc.org/blog/par-sar-and-dar-making-sense-standard-definition-sd-video-pixels">PAR, SAR, and DAR: Making Sense of Standard Definition (SD) video pixels</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
