<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类:ffmpeg源码分析 | 懒人李冰]]></title>
  <link href="http://lazybing.github.io/blog/categories/ffmpegyuan-ma-fen-xi/atom.xml" rel="self"/>
  <link href="http://lazybing.github.io/"/>
  <updated>2017-07-01T08:42:14-07:00</updated>
  <id>http://lazybing.github.io/</id>
  <author>
    <name><![CDATA[李冰]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[FFMpeg 实现视频编码、解码、封装、解封装、转码、缩放以及添加水印]]></title>
    <link href="http://lazybing.github.io/blog/2017/01/01/ffmpeg-sdk-learning/"/>
    <updated>2017-01-01T07:17:10-08:00</updated>
    <id>http://lazybing.github.io/blog/2017/01/01/ffmpeg-sdk-learning</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#ffmpeg-" id="markdown-toc-ffmpeg-">FFMpeg 编码实现</a></li>
  <li><a href="#ffmpeg--1" id="markdown-toc-ffmpeg--1">FFMpeg 解码实现</a></li>
  <li><a href="#ffmpeg--2" id="markdown-toc-ffmpeg--2">FFMpeg 封装实现</a></li>
  <li><a href="#ffmpeg--3" id="markdown-toc-ffmpeg--3">FFMpeg 解封装实现</a></li>
  <li><a href="#ffmpeg--4" id="markdown-toc-ffmpeg--4">FFMpeg 转码的实现</a></li>
  <li><a href="#ffmpeg--5" id="markdown-toc-ffmpeg--5">FFMpeg 视频缩放实现</a></li>
  <li><a href="#ffmpeg--6" id="markdown-toc-ffmpeg--6">FFMpeg 添加水印实现</a></li>
</ul>

<p><a href="&quot;https://ffmpeg.org/&quot;">FFMpeg</a> 作为音视频领域的开源工具，它几乎可以实现所有针对音视频的处理，本文主要利用 FFMpeg 官方提供的 SDK 实现音视频最简单的几个实例：编码、解码、封装、解封装、转码、缩放以及添加水印。<br />
<!--more-->
接下来会由发现问题－＞分析问题－＞解决问题－＞实现方案，循序渐进的完成。<br />
参考代码：<a href="&quot;https://github.com/lazybing/ffmpeg-study-recording&quot;">ｌａｚｙｂｉｎｇ</a></p>

<h2 id="ffmpeg-">FFMpeg 编码实现</h2>

<p>本例子实现的是将视频域 YUV 数据编码为压缩域的帧数据，编码格式包含了 H.264/H.265/MPEG1/MPEG2 四种 CODEC 类型。
实现的过程，可以大致用如下图表示:</p>

<p>{% img /images/ffmpeg_sdk/encoder.png %}</p>

<p>从图中可以大致看出视频编码的流程:</p>

<ul>
  <li>首先要有未压缩的 YUV 原始数据。</li>
  <li>其次要根据想要编码的格式选择特定的编码器。</li>
  <li>最后编码器的输出即为编码后的视频帧。</li>
</ul>

<p>根据流程可以推倒出大致的代码实现：</p>

<ul>
  <li>存放待压缩的 YUV 原始数据。此时可以利用 FFMpeg 提供的 AVFrame 结构体，并根据 YUV 数据来填充 AVFrame　结构的视频宽高、像素格式；根据视频宽高、像素格式可以分配存放数据的内存大小，以及字节对齐情况。</li>
  <li>获取编码器。利用想要压缩的格式，比如　H.264/H.265/MPEG1/MPEG2 等，来获取注册的编解码器，编解码器在 FFMpeg 中用 AVCodec 结构体表示，对于编解码器，肯定要对其进行配置，包括待压缩视频的宽高、像素格式、比特率等等信息，这些信息，FFMpeg 提供了一个专门的结构体 AVCodecContext 结构体。</li>
  <li>存放编码后压缩域的视频帧。FFMpeg 中用来存放压缩编码数据相关信息的结构体为 AVPacket。最后将 AVPacket 存储的压缩数据写入文件即可。</li>
</ul>

<hr />

<p>AVFrame 结构体的分配使用<code>av_frame_alloc()</code>函数，该函数会对 AVFrame 结构体的某些字段设置默认值，它会返回一个指向 AVFrame 的指针或 NULL指针(失败)。AVFrame 结构体的释放只能通过<code>av_frame_free()</code>来完成。注意，该函数只能分配 AVFrame 结构体本身，不能分配它的 data buffers 字段指向的内容，该字段的指向要根据视频的宽高、像素格式信息手动分配，本例使用的是<code>av_image_alloc()</code>函数。代码实现大致如下：</p>

<p>{% codeblock lang:c %}
//allocate AVFrame struct
AVFrame *frame = NULL;
frame = av_frame_alloc();
if(!frame){
	printf(“Alloc Frame Fail\n”);
	return -1;
}</p>

<p>//fill AVFrame struct fields
frame-&gt;width = width;
frame-&gt;height = height;
frame-&gt;pix_fmt = AV_PIX_FMT_YUV420P;</p>

<p>//allocate AVFrame data buffers field point
ret = av_image_alloc(frame-&gt;data, frame-&gt;linesize, frame-&gt;width, frame-&gt;height, frame-&gt;pix_fmt, 32);
if(ret &lt; 0){
	printf(“Alloc Fail\n”);
	return -1;
}</p>

<p>//write input file data to frame-&gt;data buffer
fread(frame-&gt;data[0], 1, frame-&gt;widht*frame-&gt;height, pInput_File);
…
av_frame_free(frame);
{% endcodeblock %}</p>

<hr />

<p>编解码器相关的 AVCodec 结构体的分配使用<code>avcodec_find_encoder(enum AVCodecID id)</code>完成，该函数的作用是找到一个与 AVCodecID 匹配的已注册过得编码器；成功则返回一个指向 AVCodec ID 的指针，失败返回 NULL 指针。该函数的作用是确定系统中是否有该编码器，只是能够使用编码器进行特定格式编码的最基本的条件，要想使用它，至少要完成两个步骤：</p>

<ol>
  <li>根据特定的视频数据，对该编码器进行特定的配置；</li>
  <li>打开该编码器。</li>
</ol>

<p>针对第一步中关于编解码器的特定参数，FFMpeg 提供了一个专门用来存放 AVCodec 所需要的配置参数的结构体 AVCodecContext 结构。它的分配使用<code>avcodec_alloc_context3(const AVCodec *codec)</code>完成，该函数根据特定的 CODEC 分配一个 AVCodecContext 结构体，并设置一些字段为默认参数，成功则返回指向 AVCodecContext 结构体的指针，失败则返回 NULL 指针。分配完成后，根据视频特性，手动指定与编码器相关的一些参数，比如视频宽高、像素格式、比特率、GOP 大小等。最后根据参数信息，打开找到的编码器，此处使用<code>avcodec_open2()</code>函数完成。代码实现大致如下：</p>

<p>{% codeblock lang:c %}
AVCodec *codec = NULL;
AVCodecContext *codecCtx = NULL;</p>

<p>//register all encoder and decoder
avcodec_register_all();</p>

<p>//find the encoder
codec = avcodec_find_encoder(codec_id);
if(!codec){
	printf(“Could Not Find the Encoder\n”);
	return -1;
}</p>

<p>//allocate the AVCodecContext and fill it’s fields
codecCtx = avcodec_alloc_context3(codec);
if(!codecCtx){
	printf(“Alloc AVCodecCtx Fail\n”);
	return -1;
}</p>

<p>codecCtx-&gt;bit_rate = 4000000;
codecCtx-&gt;width    = frameWidth;
codecCtx-&gt;height   = frameHeight;
codecCtx-&gt;time_base= (AVRational){1, 25};</p>

<p>//open the encoder
if(avcodec_open2(codecCtx, codec, NULL) &lt; 0){
	printf(“Open Encoder Fail\n”);
}
{% endcodeblock %}</p>

<hr />

<p>存放编码数据的结构体为 AVPacket，使用之前要对该结构体进行初始化，初始化函数为<code>av_init_packet(AVPacket *pkt)</code>，该函数会初始化 AVPacket 结构体中一些字段为默认值，但它不会设置其中的 data 和 size 字段，需要单独初始化,如果此处将 data 设为 NULL、size 设为 0，编码器会自动填充这两个字段。</p>

<p>有了存放编码数据的结构体后，我们就可以利用编码器进行编码了。FFMpeg 提供的用于视频编码的函数为<code>avcodec_encode_video2</code>,它作用是编码一帧视频数据，该函数比较复杂，单独列出如下：</p>

<p>{% codeblock lang:c %}
int avcodec_encode_video2(AVCodecContext *avctx, AVPacket *avpkt,
                          const AVFrame *frame, int *got_packet_ptr);
{% endcodeblock %}</p>

<p>它会接收来自 AVFrame-&gt;data 的视频数据，并将编码数据放到 AVPacket-&gt;data 指向的位置，编码数据大小为 AVPacket-&gt;size。</p>

<p>其参数和返回值的意义：</p>

<ul>
  <li>avctx: AVCodecContext 结构，指定了编码的一些参数；</li>
  <li>avPkt: AVPacket对象的指针，用于保存输出的码流；</li>
  <li>frame：AVFrame结构，用于传入原始的像素数据；</li>
  <li>got_packet_ptr:输出参数，用于标识是否已经有了完整的一帧；</li>
  <li>返回值：编码成功返回 0， 失败返回负的错误码；</li>
</ul>

<p>编码完成后就可将AVPacket-&gt;data内的编码数据写到输出文件中；代码实现大致如下：</p>

<p>{% codeblock lang:c %}
AVPacket pkt;</p>

<p>//init AVPacket
av_init_packet(&amp;pkt);
pkt.data = NULL;
pkt.size = 0;</p>

<p>//encode the image
ret = avcodec_encode_video2(codecCtx, &amp;pkt, frame, &amp;got_output);
if(ret &lt; 0){
	printf(“Encode Fail\n”);
	return -1;
｝</p>

<p>if(got_output){
	fwrite(pkt.data, 1, pkt.size, pOutput_File);
}
{% endcodeblock %}</p>

<p>编码的大致流程已经完成了，剩余的是一些收尾工作，比如释放分配的内存、结构体等等。</p>

<p>完整实现请移步<a href="https://github.com/lazybing/ffmpeg-study-recording/blob/master/encoder.c">编码实现</a>。</p>

<h2 id="ffmpeg--1">FFMpeg 解码实现</h2>

<p>解码实现的是将压缩域的视频数据解码为像素域的 YUV 数据。实现的过程，可以大致用如下图所示。</p>

<p>{% img /images/ffmpeg_sdk/decoder.png %}</p>

<p>从图中可以看出，大致可以分为下面三个步骤：</p>

<ul>
  <li>首先要有待解码的压缩域的视频。</li>
  <li>其次根据压缩域的压缩格式获得解码器。</li>
  <li>最后解码器的输出即为像素域的 YUV 数据。</li>
</ul>

<p>根据流程可以推倒出大致的代码实现：</p>

<ul>
  <li>关于输入数据。首先，要分配一块内存，用于存放压缩域的视频数据；之后，对内存中的数据进行预处理，使其分为一个一个的 AVPacket 结构（AVPacket 结构的简单介绍如上面的编码实现）。最后，将 AVPacket 结构中的 data 数据给到解码器。</li>
  <li>关于解码器。首先，利用 CODEC_ID 来获取注册的解码器；之后，将预处理过得视频数据给到解码器进行解码。</li>
  <li>关于输出。FFMpeg 中，解码后的数据存放在 AVFrame 中；之后就将 AVFrame 中的 data 字段的数据存放到输出文件中。</li>
</ul>

<hr />

<p>对于输入数据，首先，通过 fread 函数实现将固定长度的输入文件的数据存放到一块 buffer 内。H.264中一个包的长度是不定的，读取固定长度的码流通常不可能刚好读出一个包的长度；对此，FFMpeg 提供了一个 AVCoderParserContext 结构用于解析读到 buffer 内的码流信息，直到能够取出一个完整的 H.264 包。为此，FFMpeg 提供的函数为<code>av_parser_parse2</code>，该函数比较复杂，定义如下：</p>

<p>{% codeblock lang:c %}<br />
int av_parser_parse2(AVCodecParserContext *s,
                     AVCodecContext *avctx,
                     uint8_t **poutbuf, int *poutbuf_size,
                     const uint8_t *buf, int buf_size,
                     int64_t pts, int64_t dts,
                     int64_t pos);
{% endcodeblock %}</p>

<p>函数的参数和返回值含义如下：</p>

<ul>
  <li>AVCodecParserContext *s:初始化过的 AVCodecParserContext 对象，决定了码流该以怎样的标准进行解析；</li>
  <li>AVCodecContext *avctx：预先定义好的 AVCodecContext 对象；</li>
  <li>uint8_t **poutbuf：AVPacket：：data 的地址，保存解析完成的包数据。</li>
  <li>int *poutbuf_size：AVPacket 的实际数据长度，如果没有解析出完整的一个包，该值为 0；</li>
  <li>const uint8_t *but:待解码的码流的地址；</li>
  <li>int buf_size:待解码的码流的长度；</li>
  <li>int64_t pts, int64_t dts:显示和解码的时间戳；</li>
  <li>int64_t pos:码流中的位置；</li>
  <li>返回值为解析所使用的比特位的长度；</li>
</ul>

<p>FFMpeg 中为我们提供的该函数常用的使用方式为：</p>

<p>{% codeblock lang:c %}
while(in_len){
	len = av_parser_parse2(myparser. AVCodecContext, &amp;data, &amp;size, in_data, in len, pts, dts, pos);</p>

<pre><code>in_data += len;
in_len  -= len;

if(size)
	decode_frame(data, size); } {% endcodeblock %}
</code></pre>

<p>如果参数poutbuf_size的值为0，那么应继续解析缓存中剩余的码流；如果缓存中的数据全部解析后依然未能找到一个完整的包，那么继续从输入文件中读取数据到缓存，继续解析操作，直到pkt.size不为0为止。</p>

<p>因此，关于输入数据的处理，代码大致如下：</p>

<p>{% codeblock lang:c %}
//open input file
FILE *pInput_File = fopen(Input_FileName, “rb+”);
if(!pInput_File){
	printf(“Open Input File Fail\n”);
	return -1;
}</p>

<p>//read compressed bitstream form file to buffer
uDataSize = fread(inbuf, 1, INBUF_SIZE, pInput_File);
if(uDataSize == 0){	//decode finish
	return -1;
}</p>

<p>//decode the data in the buffer to AVPacket.data
while(uDataSize &gt; 0){
	len = av_parser_parse2(pCodecParserCtx, codecCtx,
							&amp;(pkt.data), &amp;(pkt.size),
							pDataPtr, uDataSize,
							AV_NOPTS_VALUE, AV_NOPTS_VALUE,
							AV_NOPTS_VALUE);
	uDataSize -= len;
	uDataPtr  += len;</p>

<pre><code>if(pkt.size == 0) continue;
decode_frame(pkt.data, pkt.size); } {% endcodeblock %}
</code></pre>

<p>注意，上面提到的<code>av_parser_parse2</code>函数用的几个参数，其实是与具体的编码格式有关的，它们应该在之前已经分配好了，我们只是放到后面来讲一下，因为它们是与具体的解码器强相关的。</p>

<hr />

<p>对于解码器。与上面提到的编码实现类似，首先，根据 CODEC_ID 找到注册的解码器 AVCodec，FFMpeg 为此提供的函数为<code>avcodec_find_decoder()</code>；其次，根据找到的解码器获取与之相关的解码器上下文结构体 AVCodecC，使用的函数为编码中提到的<code>avcodec_alloc_context3</code>；再者，如上面提到的要获取完整的一个 NALU，解码器需要分配一个 AVCodecParserContext 结构，使用函数<code>av_parser_init</code>；最后，前面的准备工作完成后，打开解码器，即可调用 FFMpeg 提供的解码函数<code>avcodec_decode_video2</code>对输入的压缩域的码流进行解码，并将解码数据存放到 AVFrame-&gt;data 中。代码实现大致如下：</p>

<p>{% codeblock lang:c %}
AVFrame *frame = NULL;
AVCodec *codec = NULL;
AVCodecContext *codecCtx = NULL;
AVCodecParserContext *pCodecParserCtx = NULL;</p>

<p>//register all encoder and decoder
avcodec_register_all();</p>

<p>//Allocate AVFrame to Store the Decode Data
frame = av_frame_alloc();
if(!frame){
	printf(“Alloc Frame Fail\n”);
	return -1;
}</p>

<p>//Find the  AVCodec Depending on the CODEC_ID
codec = avcodec_find_decoder(AV_CODEC_ID_H264);
if(!codec){
	printf(“Find the Decoder Fail\n”);
	return -1;
}</p>

<p>//Allocate the AVCodecContext 
codecCtx = avcodec_alloc_context3(codec);
if(!codecCtx){
	printf(“Alloc AVCodecCtx Fail\n”);
	return -1;
}</p>

<p>//Allocate the AVCodecParserContext 
pCodecParserCtx = av_parser_init(AV_CODEC_ID_H264);
if(!pCodecParserCtx){
	printf(“Alloc AVCodecParserContext Fail\n”);
	return -1;
}</p>

<p>//Open the Decoder
if(avcodec_open2(codecCtx, codec, NULL) &lt; 0){
	printf(“Could not Open the Decoder\n”);
	return -1;
}</p>

<p>//read compressed bitstream form file to buffer
uDataSize = fread(inbuf, 1, INBUF_SIZE, pInput_File);
if(uDataSize == 0){	//decode finish
	return -1;
}</p>

<p>//decode the data in the buffer to AVPacket.data
while(uDataSize &gt; 0){
	len = av_parser_parse2(pCodecParserCtx, codecCtx,
							&amp;(pkt.data), &amp;(pkt.size),
							pDataPtr, uDataSize,
							AV_NOPTS_VALUE, AV_NOPTS_VALUE,
							AV_NOPTS_VALUE);
	uDataSize -= len;
	uDataPtr  += len;</p>

<pre><code>if(pkt.size == 0) continue;
//decode start
avcodec_decode_video2(codecCtx, frame, &amp;got_frame, pkt); } {% endcodeblock %}
</code></pre>

<p>注意，上面解码的过程中，针对具体的实现，可能要做一些具体参数上的调整，此处只是理清解码的流程。</p>

<hr />

<p>对于输出数据。解码完成后，解码出来的像素域的数据存放在 AVFrame 的 data 字段内，只需要将该字段内存放的数据之间写文件到输出文件即可。解码函数<code>avcodec_decode_video2</code>函数完成整个解码过程，对于它简单介绍如下：</p>

<p>{% codeblock lang:c %}
int avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,
                         int *got_picture_ptr,
                         const AVPacket *avpkt);
{% endcodeblock lang:c %}</p>

<p>该函数各个参数的意义：</p>

<ul>
  <li>AVCodecContext *avctx：编解码器上下文对象，在打开编解码器时生成；</li>
  <li>AVFrame *picture: 保存解码完成后的像素数据；我们只需要分配对象的空间，像素的空间codec会为我们分配好；</li>
  <li>int *got_picture_ptr: 标识位，如果为1，那么说明已经有一帧完整的像素帧可以输出了;</li>
  <li>const AVPacket *avpkt: 前面解析好的码流包；</li>
</ul>

<p>由此可见，当标识位为1时，代表解码一帧结束，可以写数据到文件中。代码如下：</p>

<p>{% codeblock lang:c %}
pOutput_File = fopen(Output_FileName, “wb”);
if(!pOutput_File){
	printf(“Open Output File Fail\n”);
	return -1;
}</p>

<p>if(*got_picture_ptr){
	fwrite(frame-&gt;data[0],1, Len, pOutput_File)
}
{% endcodeblock %}</p>

<p>解码的大致流程已经完成了，剩余的是一些收尾工作，比如释放分配的内存、结构体等等。</p>

<p>完整实现请移步<a href="https://github.com/lazybing/ffmpeg-study-recording/blob/master/decoder.c">解码实现</a>。</p>

<h2 id="ffmpeg--2">FFMpeg 封装实现</h2>

<p>本例子实现的是将视频数据和音频数据，按照一定的格式封装为特定的容器，比如FLV、MKV、MP4、AVI等等。实现的过程，可以大致用如下图表示：</p>

<p>{% img /images/ffmpeg_sdk/muxer.png %}</p>

<p>从图中可以大致看出视频封装的流程：</p>

<ul>
  <li>首先要有编码好的视频、音频数据。</li>
  <li>其次要根据想要封装的格式选择特定的封装器。</li>
  <li>最后利用封装器进行封装。</li>
</ul>

<p>根据流程可以推倒出大致的代码实现：</p>

<ul>
  <li>利用给定的YUV数据编码得到某种 CODEC 格式的编码视频（可以参见上面提到的<a href="http://lazybing.github.io/blog/2017/01/01/ffmpeg-sdk-learning/#ffmpeg-">编码实现</a>），同样的方法得到音频数据。</li>
  <li>获取输出文件格式。获取输出文件格式可以直接指定文件格式，比如FLV/MKV/MP4/AVI等，也可以通过输出文件的后缀名来确定，或者也可以选择默认的输出格式。根据得到的文件格式，其中可能有视频、音频等，为此我们需要为格式添加视频、音频、并对格式中的一些信息进行设置（比如头）。</li>
  <li>利用设置好的音频、视频、头信息等，开始封装。</li>
</ul>

<hr />

<p>对于由 YUV 数据得到编码的视频数据部分，不再重复。直接看与 Muxer 相关的部分，与特定的 Muxer 相关的信息，FFMpeg 提供了一个 AVFormatContext 的结构体描述，并用<code>avformat_alloc_output_context2()</code>函数来分配它。该函数的声明如下：</p>

<p>{% codeblock lang:c %}
int avformat_alloc_output_context2(AVFormatContext **ctx, AVOutputFormat *oformat,
                                   const char *format_name, const char *filename);
{% endcodeblock %}</p>

<p>其中：</p>

<ul>
  <li>ctx:输出到 AVFormatContext 结构的指针，如果函数失败则返回给该指针为 NULL。</li>
  <li>oformat：指定输出的 AVOutputFormat 类型，如果设为 NULL，则根据 format_name 和 filename 生成。</li>
  <li>format_name:输出格式的名称，如果设为 NULL，则使用 filename 默认格式。</li>
  <li>filename：目标文件名，如果不使用，可以设为 NULL。</li>
  <li>返回值：&gt;=0 则成功，否则失败。</li>
</ul>

<p>代码如下：</p>

<p>{% codeblock lang:c %}
AVOutputFormat *fmt;
AVFormatContext *oc;</p>

<p>/* allocate the output media context */
avformat_alloc_output_context2(&amp;oc, NULL, NULL, filename);
if (!oc) {
    printf(“Could not deduce output format from file extension: using MPEG.\n”);
    avformat_alloc_output_context2(&amp;oc, NULL, “mpeg”, filename);
}
if (!oc)
    return 1;</p>

<p>fmt = oc-&gt;oformat;
{% endcodeblock %}</p>

<p>有了表示媒体文件格式的 AVFormatContext 结构后，就需要根据媒体格式来判断是否需要往媒体文件中添加视频流、音频流（有的媒体文件，这两种流并不是必须的）；以 MP4 格式的媒体文件为例，我们需要一路视频流、一路音频流。因此需要创建一路流，FFMpeg 提供的创建流的函数为<code>avformat_new_stream()</code>，该函数完成向 AVFormatContext 结构体中所代码的媒体文件中添加数据流，函数声明如下：</p>

<p>{% codeblock lang:c %}
AVStream *avformat_new_stream(AVFormatContext *s, const AVCodec *c);
{% endcodeblock %}</p>

<p>其中：</p>

<ul>
  <li>s:AVFormatContext 结构，表示要封装生成的视频文件。</li>
  <li>c：视频或音频流的编码器的指针。</li>
  <li>返回值：指向生成的 stream 对象的指针；失败则返回 NULL。</li>
</ul>

<p>注意：对于 Muxer，该函数必须在调用<code>avformat_write_header()</code>前调用。使用完成后，需要调用<code>avcodec_close()</code>和<code>avformat_free_context()</code>来清理由它分配的内容。</p>

<p>该函数调用完成后，一个新的 AVStream 便已经加入到输出文件中，下面就需要设置 stream 的 id 和 codec 等参数。以视频流为例，代码如下：</p>

<p>{% codeblock lang:c %}
OutputStream *ost;
AVFormatContext *oc;
AVCodec **codec;
AVCodecContext *c;
AVStream *st;</p>

<p>st = avformat_new_stream(oc, *codec);
if(!st){
    fprintf(stderr, “Could not allocate stream\n”);
    exit(1);
}
st-&gt;id = oc-&gt;nb_streams-1;
c = st-&gt;codec;
{% endcodeblock %}</p>

<p>参数设置完成后，就可以打开编码器并为编码器分配必要的内存。步骤跟之前的类似，以视频为例，示例代码如下：</p>

<p>{% codeblock lang:c %}
//open the codec
ret = avcodec_open(c, codec, &amp;opt);
if(ret &lt; 0){
    fprintf(stderr, “Could not open video codec: %s\n”, av_err2str(ret));
    exit(1);
}
//allocate and init a re-usable frame
ost-&gt;frame = alloc_picture(c-&gt;pix_fmt, c-&gt;width, c-&gt;height);
{% endcodeblock %}</p>

<p>接下来进行真正的封装：首先，为媒体文件添加头部信息,FFMpeg 为此提供的函数为<code>avformat_write_header()</code>。其次，将编码好的音视频 AVPacket 包添加到媒体文件中去，FFMpeg 为此提供的函数为<code>av_interleaved_write_frame()</code>。最后，写入文件尾的数据，FFMpeg 为此提供的函数为<code>av_write_trailer()</code>。</p>

<p>封装的大致流程已经完成了，剩余的是一些收尾工作，比如释放分配的内存、结构体等等。</p>

<p>完整实现请移步<a href="https://github.com/lazybing/ffmpeg-study-recording/blob/master/muxer.c">封装实现</a>。</p>

<p>{% video https://github.com/lazybing/lazybing.github.io/blob/source/images/ffmpeg.mp4 640 320 %}</p>

<h2 id="ffmpeg--3">FFMpeg 解封装实现</h2>

<h2 id="ffmpeg--4">FFMpeg 转码的实现</h2>

<h2 id="ffmpeg--5">FFMpeg 视频缩放实现</h2>

<h2 id="ffmpeg--6">FFMpeg 添加水印实现</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FFMPEG 源码分析：avformat_find_stream_info]]></title>
    <link href="http://lazybing.github.io/blog/2016/12/25/avformat_find_stream_info/"/>
    <updated>2016-12-25T06:18:07-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/12/25/avformat_find_stream_info</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">函数声明</a></li>
  <li><a href="#section-1" id="markdown-toc-section-1">调用关系</a></li>
</ul>

<p><code>avformat_find_stream_info</code>主要是读媒体文件的包(packets)，然后从中提取出流的信息。
对于没有头部信息的文件格式尤其有用，比如<code>MPEG</code>。文件的逻辑位置不会被改变，读取出来
的包会被缓存起来供以后处理。</p>

<!--more-->

<h2 id="section">函数声明</h2>

<p><code>
int avformat_find_stream_info(AVFormatContext *ic, AVDictionary **options);
</code>
返回值：&gt;=0–&gt;OK,或出错返回AVERROR_xxx</p>

<p>注意，该函数并不保证能够打开所有的 codec，因此将options 设置为非NULL用于返回一些信息是非常好的行为。</p>

<h2 id="section-1">调用关系</h2>

<p><img src="http://lazybing.github.io/images/avformat_find_stream_info/avformat_find_stream_info.png" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FFMPEG 源码分析：avcodec_decode_video2]]></title>
    <link href="http://lazybing.github.io/blog/2016/12/20/avcodec_decode_video/"/>
    <updated>2016-12-20T06:18:07-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/12/20/avcodec_decode_video</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">函数声明</a></li>
  <li><a href="#section-1" id="markdown-toc-section-1">源码分析</a></li>
</ul>

<p><code>avcodec_decode_video</code>函数的作用是解码<code>AVPacket</code>中的压缩数据，解码为图像数据。
某些解码器支持在一个<code>AVPacket</code>中包含多帧，这类的解码器只解码第一帧。</p>

<!--more-->

<h2 id="section">函数声明</h2>

<p><code>
int avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,
                         int *got_picture_ptr,
                         const AVPacket *avpkt);
</code></p>

<p>注意，输入内存的对齐字节(AV_INPUT_BUFFER_PADDING_SIZE)比实际读取字节要大，因为某些
最优流可能会读取 32 或 64 bits 每次。</p>

<p>在将压缩数据packets给到解码器之前，<code>AVCodecContext</code>必须用<code>avcodec_open2</code>设置过。</p>

<p>函数参数：</p>

<ul>
  <li><code>AVCodecContext *</code>。</li>
  <li><code>AVFrame *</code>存放解码的视频数据，它使用<code>av_frame_alloc</code>获得一个<code>AVFrame</code>。解码器会调用
<code>AVCodecContext.get_buffer2</code>回调函数为实际的位图分配内存。</li>
  <li><code>got_picture_ptr</code>,如果没有帧可以解码，该值被设为0。否则，它是非零值。</li>
  <li><code>AVPacket *</code>包含输入缓存。该结构体使用<code>av_init_packet</code>创建后会设置<code>data</code>和<code>size</code>，某些
解码器可能需要更多的字段,如<code>flags &amp; AV_PKT_FLAG_KEY</code>。解码器被设置为使用最少的字段。</li>
</ul>

<p>返回值：如果解码出错，返回负值；否则返回使用的字节数。</p>

<h2 id="section-1">源码分析</h2>

<p><code>avcodec_decode_video2</code>函数比较简单，主要做了以下几个工作：</p>

<ol>
  <li>对输入的字段进行一些列的检查工作，比如宽高是否正确，输入是否为视频等等。</li>
  <li>真正的解码，通过<code>avctx-&gt;codec-&gt;decode</code>实现，它会调用相应的<code>AVCodec</code>的 decode 函数，完成解码。</li>
  <li>对得到的<code>AVFrame</code>进行一些字段进行赋值，例如宽高、像素格式等等。</li>
</ol>

<p>{% codeblock lang:c avcodec_decode_video2 %}
int attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,
                                              int *got_picture_ptr,
                                              const AVPacket *avpkt)
{
    …
    //检测输入参数
    if (!avctx-&gt;codec)
        return AVERROR(EINVAL);
    if (avctx-&gt;codec-&gt;type != AVMEDIA_TYPE_VIDEO) {
        av_log(avctx, AV_LOG_ERROR, “Invalid media type for video\n”);
        return AVERROR(EINVAL);
    }</p>

<pre><code>*got_picture_ptr = 0;
if ((avctx-&gt;coded_width || avctx-&gt;coded_height) &amp;&amp; av_image_check_size(avctx-&gt;coded_width, avctx-&gt;coded_height, 0, avctx))
    return AVERROR(EINVAL);

...
//真正的解码
ret = avctx-&gt;codec-&gt;decode(avctx, picture, got_picture_ptr,
        &amp;tmp);

...
//设置参数
if (!(avctx-&gt;codec-&gt;capabilities &amp; AV_CODEC_CAP_DR1)) {
    if (!picture-&gt;sample_aspect_ratio.num)    picture-&gt;sample_aspect_ratio = avctx-&gt;sample_aspect_ratio;
        if (!picture-&gt;width)                      picture-&gt;width               = avctx-&gt;width;
        if (!picture-&gt;height)                     picture-&gt;height              = avctx-&gt;height;
        if (picture-&gt;format == AV_PIX_FMT_NONE)   picture-&gt;format              = avctx-&gt;pix_fmt;
}
... } {% endcodeblock %}
</code></pre>

<p>以H.265解码器为例，解码示例如下：</p>

<p>{% codeblock lang:c ff_hevc_decoder %}
AVCodec ff_hevc_decoder = {
    .name                  = “hevc”,
    .long_name             = NULL_IF_CONFIG_SMALL(“HEVC (High Efficiency Video Coding)”),
    .type                  = AVMEDIA_TYPE_VIDEO,
    .id                    = AV_CODEC_ID_HEVC,
    .priv_data_size        = sizeof(HEVCContext),
    .priv_class            = &amp;hevc_decoder_class,
    .init                  = hevc_decode_init,
    .close                 = hevc_decode_free,
    .decode                = hevc_decode_frame,
    .flush                 = hevc_decode_flush,
    …
};
{% endcodeblock %}</p>

<p>其中<code>hevc_decode_frame</code>是解码器的真正的解码函数，定义如下：<br />
{% codeblock lang:c hevc_decode_frame %}
static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
                             AVPacket *avpkt)
{
    int ret;
    HEVCContext *s = avctx-&gt;priv_data;</p>

<pre><code>if (!avpkt-&gt;size) {
    ret = ff_hevc_output_frame(s, data, 1);
    if (ret &lt; 0)
        return ret;

    *got_output = ret;
    return 0;
}

s-&gt;ref = NULL;
ret    = decode_nal_units(s, avpkt-&gt;data, avpkt-&gt;size);
if (ret &lt; 0)
    return ret;

if (avctx-&gt;hwaccel) {
    if (s-&gt;ref &amp;&amp; (ret = avctx-&gt;hwaccel-&gt;end_frame(avctx)) &lt; 0) {
        av_log(avctx, AV_LOG_ERROR,
               "hardware accelerator failed to decode picture\n");
        ff_hevc_unref_frame(s, s-&gt;ref, ~0);
        return ret;
    }
} else {
    /* verify the SEI checksum */
    if (avctx-&gt;err_recognition &amp; AV_EF_CRCCHECK &amp;&amp; s-&gt;is_decoded &amp;&amp;
        s-&gt;is_md5) {
        ret = verify_md5(s, s-&gt;ref-&gt;frame);
        if (ret &lt; 0 &amp;&amp; avctx-&gt;err_recognition &amp; AV_EF_EXPLODE) {
            ff_hevc_unref_frame(s, s-&gt;ref, ~0);
            return ret;
        }
    }
}
s-&gt;is_md5 = 0;

if (s-&gt;is_decoded) {
    av_log(avctx, AV_LOG_DEBUG, "Decoded frame with POC %d.\n", s-&gt;poc);
    s-&gt;is_decoded = 0;
}

if (s-&gt;output_frame-&gt;buf[0]) {
    av_frame_move_ref(data, s-&gt;output_frame);
    *got_output = 1;
}

return avpkt-&gt;size; } {% endcodeblock %}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FFMPEG 源码分析：av_read_frame]]></title>
    <link href="http://lazybing.github.io/blog/2016/12/15/av_read_frame/"/>
    <updated>2016-12-15T06:18:07-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/12/15/av_read_frame</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">函数声明</a></li>
  <li><a href="#section-1" id="markdown-toc-section-1">函数调用关系</a></li>
  <li><a href="#section-2" id="markdown-toc-section-2">源码分析</a></li>
</ul>

<p><code>av_read_frame</code>函数的作用是返回文件中保存的数据。它会文件中保存的数据分成不同的帧，
每次调用都会返回一帧。注意，该函数不会忽略帧与帧之间无效数据(非帧数据)，目的是给解码器
最多的信息用于解码。</p>

<!--more-->

<h2 id="section">函数声明</h2>

<p><code>
int av_read_frame(AVFormatContext *s, AVPacket *pkt);
</code></p>

<p>如果<code>pkt-&gt;buf</code>是 NULL,包直到下一次调用<code>av_read_frame</code>或<code>avformat_close_input</code>时都是有效的。
不需要时，包必须通过<code>av_free_packet</code>释放。对于视频，<code>packet</code>只包含一帧；对于音频，如果每帧有固定大小(如 PCM 或 ADPCM 数据)，
<code>packet</code>可以包含多个音频帧（必须是整数帧）,如果音频帧大小可变(如MPEG 音频)，它只能包含一帧数据。</p>

<p><code>pkt-&gt;pts</code><code>pkt-&gt;dts</code><code>pkt-&gt;duration</code>都是以<code>AVStream.time_base_units</code>为单位的。
如果视频格式里包含 B 帧，<code>pkt-&gt;pts</code>可以是<code>AV_NOPTS_VALUE</code>,因此如果不解压缩数据，最好
查看<code>pkt-&gt;dts</code>。</p>

<p>如果函数返回0，正确；小于0，则为到文件尾或出错。</p>

<h2 id="section-1">函数调用关系</h2>

<p><img src="http://lazybing.github.io/images/av_read_frame/av_read_frame.png" /></p>

<h2 id="section-2">源码分析</h2>

<p><code>av_read_frame</code>函数会判断在未解码缓存中是否有数据，如果有数据则调用<code>read_from_packet_buffer</code>。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FFMPEG 源码分析：avcodec_open2]]></title>
    <link href="http://lazybing.github.io/blog/2016/12/10/avcodec-open2/"/>
    <updated>2016-12-10T06:18:07-08:00</updated>
    <id>http://lazybing.github.io/blog/2016/12/10/avcodec-open2</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">函数声明</a></li>
  <li><a href="#section-1" id="markdown-toc-section-1">函数使用示例</a></li>
  <li><a href="#section-2" id="markdown-toc-section-2">函数源码分析</a></li>
</ul>

<p><code>avcodec_open2</code>函数实现的功能为利用给定的<code>AVCodec</code>结构初始化<code>AVCodecContext</code>结构。</p>

<!--more-->

<h2 id="section">函数声明</h2>

<p><code>avcodec_open2</code>的声明如下:</p>

<p><code>
int avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options);
</code></p>

<p>函数参数说明：</p>

<ul>
  <li>avctx:需要初始化的context.</li>
  <li>codec:</li>
  <li>options:</li>
  <li>返回值：如果返回0，正确。失败则返回负数。</li>
</ul>

<p>该函数利用给定的<code>AVCodec</code>结构初始化<code>AVCodecContext</code>结构，在使用该函数之前，<code>AVCodecContext</code>
必须已经用<code>avcodec_alloc_context3()</code>函数分配出来。</p>

<p><code>AVCodec</code>结构在使用该函数之前，由<code>avcodec_find_decoder_by_name</code><code>avcodec_find_encoder_by_name</code>
<code>avcodec_find_decoder</code>或<code>avcodec_find_encoder</code>提前得到。</p>

<p>注意，在正式解码之前(比如使用<code>avcodec_decode_video2()</code>之前)，必须调用<code>avcodec_open2</code>函数。</p>

<h2 id="section-1">函数使用示例</h2>

<p>示例代码如下：</p>

<p>{% codeblock lang:c %}
avcodec_register_all();
av_dict_set(&amp;opt, “b”, “2.5M”, 0);
codec = avcodec_find_decoder(AV_CODEC_ID_H264);
if(!codec)
    exit(1);</p>

<p>context = avcodec_alloc_context3(codec);</p>

<p>if(avcodec_open2(context, codec, opts) &lt; 0)
    exit(1);
{% endcodeblock %}</p>

<h2 id="section-2">函数源码分析</h2>

<p><code>avcodec_open2</code>的逻辑非常简单，首先是进行一些参数检测、之后调动<code>AVCodec</code>的init函数。大概步骤如下：</p>

<ul>
  <li>各种函数参数检测。</li>
  <li>各种结构体分配内存。</li>
  <li>将输入的<code>AVDictionary</code>形式的选项设置到<code>AVCodecContext</code>。</li>
  <li>其他一些零散的查，检查输入参数是否符合编码器的要求。</li>
  <li>调用<code>AVCodec</code>的init函数初始化具体的解码器。</li>
</ul>

<p>此处重点分析调用<code>AVCodec</code>的init函数处。 以 HEVC 解码器为例。</p>

<p>{% codeblock lang:c %}
AVCodec ff_hevc_decoder = {
    .name                  = “hevc”,
    .long_name             = NULL_IF_CONFIG_SMALL(“HEVC (High Efficiency Video Coding)”),
    .type                  = AVMEDIA_TYPE_VIDEO,
    .id                    = AV_CODEC_ID_HEVC,
    .priv_data_size        = sizeof(HEVCContext),
    .priv_class            = &amp;hevc_decoder_class,
    .init                  = hevc_decode_init,
    .close                 = hevc_decode_free,
    .decode                = hevc_decode_frame,
    .flush                 = hevc_decode_flush,
    .update_thread_context = hevc_update_thread_context,
    .init_thread_copy      = hevc_init_thread_copy,
    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_DELAY |
                             AV_CODEC_CAP_SLICE_THREADS | AV_CODEC_CAP_FRAME_THREADS,
    .profiles              = NULL_IF_CONFIG_SMALL(profiles),
};
{% endcodeblock %}</p>

<p>其中 init 函数定义如下：</p>

<p>{% codeblock lang:c %}
static av_cold int hevc_decode_init(AVCodecContext *avctx)
{
    HEVCContext *s = avctx-&gt;priv_data;
    int ret;</p>

<pre><code>ff_init_cabac_states();

avctx-&gt;internal-&gt;allocate_progress = 1;

ret = hevc_init_context(avctx);
if (ret &lt; 0)
    return ret;

s-&gt;enable_parallel_tiles = 0;
s-&gt;picture_struct = 0;

if(avctx-&gt;active_thread_type &amp; FF_THREAD_SLICE)
    s-&gt;threads_number = avctx-&gt;thread_count;
else
    s-&gt;threads_number = 1;

if (avctx-&gt;extradata_size &gt; 0 &amp;&amp; avctx-&gt;extradata) {
    ret = hevc_decode_extradata(s);
    if (ret &lt; 0) {
        hevc_decode_free(avctx);
        return ret;
    }
}

if((avctx-&gt;active_thread_type &amp; FF_THREAD_FRAME) &amp;&amp; avctx-&gt;thread_count &gt; 1)
        s-&gt;threads_type = FF_THREAD_FRAME;
    else
        s-&gt;threads_type = FF_THREAD_SLICE;

return 0; } {% endcodeblock %}
</code></pre>

]]></content>
  </entry>
  
</feed>
