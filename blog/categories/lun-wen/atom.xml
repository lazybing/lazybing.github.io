<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类:论文 | 懒人李冰]]></title>
  <link href="http://lazybing.github.io/blog/categories/lun-wen/atom.xml" rel="self"/>
  <link href="http://lazybing.github.io/"/>
  <updated>2021-07-04T08:15:16-07:00</updated>
  <id>http://lazybing.github.io/</id>
  <author>
    <name><![CDATA[李冰]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Intra-frame Prediction Algorithm]]></title>
    <link href="http://lazybing.github.io/blog/2021/05/26/intra-frame-algorithm/"/>
    <updated>2021-05-26T07:38:25-07:00</updated>
    <id>http://lazybing.github.io/blog/2021/05/26/intra-frame-algorithm</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#intra-frame-prediction-elements" id="markdown-toc-intra-frame-prediction-elements">Intra-Frame Prediction Elements</a></li>
  <li><a href="#the-existing-intra-frame-prediction-algorithm-flows-and-questions" id="markdown-toc-the-existing-intra-frame-prediction-algorithm-flows-and-questions">The Existing Intra-Frame Prediction Algorithm Flows And Questions</a></li>
</ul>

<p>本论文详细分析了帧内预测算法的原则和流程，同时提出了一个提升算法，并阐述了优势。通过实现关于H.264/AVC的标准和和应用实验，证明算法具有实用价值和促进作用。</p>

<p>“Intra-frame Prediction Algorithm Based on the H.264/AVC Research and Improvement”</p>

<!--more-->

<h2 id="introduction">Introduction</h2>

<p>在帧内编码的过程中，有很多帧内预测模式已被采用提高效率。通过这种方法，空间图像信息的冗余将被删除。亮度预测被分为四个部分，它们分别是 4x4 帧内预测、16x16 帧内预测、8x8 帧内预测和 I-PCM 模式。</p>

<p>4x4 模式用于小的预测宏块，来处理详细而复杂的图像。在图像编码中，处理平坦区域使用更大的宏块的帧内 16x16 模式。I-PCM 模式是一个特别模式，它在特殊情况下使用，当原始数据直接传输比预测编码传输还要低时使用。帧内 8x8 预测用于高清，这个是在 2005 年提出的预测。拉格朗日 RD 模型，决定在正确的时间选择。</p>

<h2 id="intra-frame-prediction-elements">Intra-Frame Prediction Elements</h2>

<p>帧内预测编码使用图像信息字段的相关性以压缩冗余。它基于在宏块的边界上，主要是指左边宏块、上方宏块和右方宏块来预测当前宏块。之后进行 DCT 和量化，从而达到压缩编码的目的。</p>

<p>在编码过程中，有时需要根据具体的算法和 RDO 模型来选择最终成本最低的预测模式。</p>

<p>16x16 亮度采用垂直预测(模型 0)、水平预测(模型 1)、DC 预测(模型 2)、平面预测(模型 3)。这些预测模式均小于 4x4 亮度。通过 16x16 宏块通常是应用到简单的场景，并且没有很多细节。因此不需要支持多个纹理预测，亮度很可能与预测模式不同，唯一的区别是模型码。</p>

<p>为了减少标准中 4x4 预测模式差异带来的额外信息，采用了一种将帧内预测信息转换为信号模式的方法，从而实现基本信息压缩。</p>

<h2 id="the-existing-intra-frame-prediction-algorithm-flows-and-questions">The Existing Intra-Frame Prediction Algorithm Flows And Questions</h2>

<p>对一对 16x16 亮度和两个 8x8 亮度宏块的 RDO 帧内预测模式的完全搜索如下：</p>

<p>1).</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hacking VMAF With Video Color and Contrast Distortion]]></title>
    <link href="http://lazybing.github.io/blog/2020/06/30/hack-vmaf/"/>
    <updated>2020-06-30T04:57:24-07:00</updated>
    <id>http://lazybing.github.io/blog/2020/06/30/hack-vmaf</id>
    <content type="html"><![CDATA[
<p>视频质量测量在许多应用中占有重要的地位。全参考质量指标(通常被用在视频编解码比较中)将反映视频中的任何变换。在这篇文章中，我们考虑经过不同颜色校正的压缩视频，它会增加全参考度量 VMAF，同时，几乎不减少其他广泛使用的度量 SSIM。所提出的视频对比度增强方法显示了该度量在某些情况下，对视频编解码器比较的适用性，因为它可以通过调整来改进该度量值，从而在比较中作弊。</p>

<p><strong>关键字</strong>：<strong>视频质量</strong>、<strong>质量度量</strong>、<strong>视频编解码压缩</strong>、<strong>质量调节</strong>、<strong>参考特征</strong>、<strong>颜色校正</strong></p>

<!--more-->

<p>未完待续</p>

]]></content>
  </entry>
  
</feed>
