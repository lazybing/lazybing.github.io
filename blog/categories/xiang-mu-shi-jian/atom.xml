<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 项目实践 | 懒人李冰]]></title>
  <link href="http://lazybing.github.io/blog/categories/xiang-mu-shi-jian/atom.xml" rel="self"/>
  <link href="http://lazybing.github.io/"/>
  <updated>2016-06-27T06:26:10-07:00</updated>
  <id>http://lazybing.github.io/</id>
  <author>
    <name><![CDATA[李冰]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[FFmpeg 和 SDL 使用教程]]></title>
    <link href="http://lazybing.github.io/blog/2016/05/10/an-ffmpeg-and-sdl-tutorial/"/>
    <updated>2016-05-10T16:45:03-07:00</updated>
    <id>http://lazybing.github.io/blog/2016/05/10/an-ffmpeg-and-sdl-tutorial</id>
    <content type="html"><![CDATA[<p><a href="https://ffmpeg.org/">FFmpeg</a> 是制作视频应用或一般工具的非常棒的库。<a href="https://www.libsdl.org/">SDL</a> 通过封装复杂的视音频底层交互工作，降低了视音频的处理难度。</p>

<p>本文就记录一下利用 FFmpeg 和 SDL 制作简单播放器的详细步骤。<!--more--></p>

<h3>介绍</h3>

<p>对于一个视音频文件，可以从外到内的依次分为几个层面：container、stream、packets、frames.其中 container 就是平时说的<code>.avi</code> <code>.flv</code> <code>.mkv</code>等等。stream可能是 <code>video</code>、可能是 <code>audio</code>、也可能是 <code>subtitle</code>，一个文件里面可能包含多个 <code>video</code> <code>audio</code> <code>subtitle</code>。packets 是从 stream 里得到的，通常会包含一个 <code>video frame</code> 或多个 <code>audio frame</code>。</p>

<p>视音频的处理就是按照这几个层级处理的，以 <code>.avi</code> 为例大概步骤如下：</p>

<pre><code>1. OPEN video_stream FROM video.avi

2. READ packet FROM video_stream INTO frame

3. IF frame NOT COMPLETE GOTO 2

4. DO SOMETHING WITH frame

5. GOTO 2
</code></pre>

<p>当然，步骤 4 中的"DO SOMETHING"可能非常复杂，我们先简单的把得到的 frames 写到一个 PPM 文件中。</p>

<hr />

<h4>打开文件</h4>

<p>想要利用FFmpeg，你必须首先初始化库。
{% codeblock lang:c %}
int main(int argc, char *argv[]){
av_register_all();
{% endcodeblock %}
<code>av_register_all()</code>用于注册所有编译过的<code>muxers</code> <code>demuxers</code>和<code>protocols</code>，同时，该函数还会调用<code>avcodec_register_all()</code>注册所有的音视频 codec。</p>

<p>现在就可以打开视频文件了。
{% codeblock lang:c %}
AVFormatContext *pFormatCtx = NULL;</p>

<p>//open video file
if(avformat_open_input(&amp;pFormatCtx, argv[1], NULL, 0, NUL) != 0)
    return -1; //Couldn&rsquo;t open file
{% endcodeblock %}
调用函数 <code>avformat_open_input</code>,该函数读取文件头部，并将文件的格式信息存储到<code>AVFormatContext</code>结构中。最后的三个参数分别用于指定文件格式、内存大小和格式选项，此处设为<code>NULL</code>或 0，<code>libavformat</code>能够自动侦测到。</p>

<p>该函数只是简单的查看头部信息，接下来我们需要文件中码流的信息：
{% codeblock lang:c %}
//Retrieve stream information
if(avformat_find_stream_info(pFormatCtx, NULL) &lt; 0)
    return -1;  //Couldn&rsquo;t find stream information
{% endcodeblock %}
该函数用适当的信息填充<code>pFormatCtx-&gt;streams</code>。此处介绍一个便于调试的函数来看一下里面的内容：
{% codeblock lang:c %}
//Dump information about file onto standard error
av_dump_format(pFormatCtx, 0, argv[1], 0);
{% endcodeblock %}
现在<code>pFormatCtx-&gt;streams</code>仅仅是一个数组指针，数组大小为<code>pFormatCtx-&gt;nb_streams</code>,遍历该数组直到找到一个视频流。
{% codeblock lang:c %}
int i;
AVCodecContext <em>pCodecCtxOrig = NULL;
AVCodecContext </em>pCodecCtx     = NULL;</p>

<p>//Find the first video stream
videoStream = -1;
for(i = 0; i &lt; pFormatCtx->nb_streams; i++)
    if(pFormatCtx->streams[i]->codec->codec_type = AVMEDIA_TYPE_VIDEO){
        videoStream = i;
        break;
    }
if(videoStream == -1)
    return -1; //Didn&rsquo;t find a video stream</p>

<p>// Get a pointer to the codec context for the video stream
pCodecCtx = pFormatCtx->streams[videoStream]->codec;
{% endcodeblock %}
关于<code>codec</code>的流信息我们称之为<code>codec context</code>。它包含了关于流使用的该<code>codec</code>的所有信息，并且我们有一个指针指向它。但我们必须找到实际的codec并打开它：
{% codeblock lang:c %}
AVCodec *pCodec = NULL;</p>

<p>// Find the decoder for the video stream
pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
if(pCodec == NULL){
    fprintf(stderr, &ldquo;Unsupported codec!\n&rdquo;);
    return -1;  // Codec not found
}</p>

<p>// Copy context
pCodecCtx = avcodec_alloc_context3(pCodec);
if(avcodecc_copy_context(pCodecCtx, pCodecCtxOrig) != 0){
    fprintf(stderr, &ldquo;Couldn&rsquo;t copy codec context&rdquo;);
    return -1;  // Error copying codec context
}</p>

<p>//Open codec
if(avcodec_open2(pCodecCtx, pCodec) &lt; 0)
    return -1;  // Could not open codec
{% endcodeblock %}
因为不能直接使用视频流的<code>AVCodecContext</code>！因此必须使用<code>avcodec_copy_context()</code>来 copy 该 context 到一个新位置。</p>

<hr />

<h4>存储数据</h4>

<p>现在我们需要一块内存来真实的存储这些帧：
{% codeblock lang:c %}
AVFrame *pFrame = NULL;</p>

<p>//Allocate video frame
pFrame = av_frame_alloc();
{% endcodeblock %}
既然我们想要输出 PPM 文件（被存储为 24-bit RGB），我们必须将帧从它原本格式转换为 RGB。FFmpeg 可以为我们做这种转换。对于大多数项目，会将初始帧转换为特定格式。让我们分配一帧来为转换帧。
{% codeblock lang:c %}
// Allocate an AVFrame structure
pFrameRGB = av_frame_alloc();
if(pFrameRGB == NULL)
    return -1;
{% endcodeblock %}
尽管我们已经分配了帧，仍然需要一块内存存放 raw data 信息。我们使用 avpicture_get_size 来获得我们需要的大小，并手动分配该内存。
{% codeblock lang:c %}
uint8_t <em>buffer = NULL;
int numBytes;
//Determine required buffer size and allocate buffer
numBytes = avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width, pCodecCtx->height);
buffer = (uint8_t </em>)av_malloc(numBytes * sizeof(uint8_t));
{% endcodeblock %}
<code>av_malloc</code>是 FFmpeg 的分配函数，它简单封装了 malloc 函数并做内存对齐，并不会保护内存泄漏、多次释放内存或者其他分配问题。</p>

<p>现在我们使用<code>avpicture_fill</code>来将帧和新分配的内存联系起来。关于<code>AVPicture</code>强制转换：<code>AVPicture</code>结构是<code>AVFrame</code>结构体的子集——<code>AVFrame</code>结构的开始对于<code>AVPicture</code>结构来说是唯一的。
{% codeblock lang:c %}
// Assign appropriate parts of buffer to image planes in pFrameRGB
// Note that pFrameRGB is an AVFrame, but AVFrame is a superset of AVPicture
avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24, pCodecCtx->width, pCodecCtx->height);
{% endcodeblock %}
最后，我们读取码流。</p>

<hr />

<h4>读数据</h4>

<p>我们接下来要做的就是通过读<code>packet</code>中的整个视频流，解码到帧，一旦我们的帧完成后，就转换并保存它。
{% codeblock lang:c %}
struct SwsContext *sws_ctx = NULL;
int frameFinished;
AVPacket packet;
// initialize SWS context for software scaling
sws_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix_fmt, pCodecCtx->width, pCodecCtx->height, PIX_FMT_RGB24, SWS_BILINEAR, NULL, NULL, NULL);</p>

<p>i = 0;
while(av_read_frame(pFormatCtx, &amp;packet) >= 0){
    // Is this a packet from the video stream?
    if(packet.stream_index == videoStream){
        //Decode video frame
        avcodec_decode_video2(pCodecCtx, pFrame, &amp;frameFinished, &amp;packet);</p>

<pre><code>    //Did we get a video frame?
    if(frameFinished){
        //Convert the image from its native format to RGB
        sws_scale(sws_ctx, (uint8_t const * contst *)pFrame-&gt;data, pFrame-&gt;linesize, 0, pCodecCtx-&gt;height, pFrameRGB-&gt;data, pFrameRGB-&gt;linesize);

        // Save the frame to disk
        if(++i &lt;= 5)
        SaveFrame(pFrameRGB, pCodecCtx-&gt;widht, pCodecCtx-&gt;height, i);
    }
}
// Free the packet that was allocated by av_read_frame
av_free_packet(&amp;packet);
</code></pre>

<p>}
{% endcodeblock %}</p>
]]></content>
  </entry>
  
</feed>
