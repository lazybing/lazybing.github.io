<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 项目实践 | 懒人李冰]]></title>
  <link href="http://lazybing.github.io/blog/categories/xiang-mu-shi-jian/atom.xml" rel="self"/>
  <link href="http://lazybing.github.io/"/>
  <updated>2016-12-06T07:21:09-08:00</updated>
  <id>http://lazybing.github.io/</id>
  <author>
    <name><![CDATA[李冰]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[FFmpeg 和 SDL 使用教程（一）]]></title>
    <link href="http://lazybing.github.io/blog/2016/05/10/an-ffmpeg-and-sdl-tutorial/"/>
    <updated>2016-05-10T16:45:03-07:00</updated>
    <id>http://lazybing.github.io/blog/2016/05/10/an-ffmpeg-and-sdl-tutorial</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section" id="markdown-toc-section">介绍</a></li>
  <li><a href="#section-1" id="markdown-toc-section-1">打开文件</a></li>
  <li><a href="#section-2" id="markdown-toc-section-2">存储数据</a></li>
  <li><a href="#section-3" id="markdown-toc-section-3">读取数据</a></li>
  <li><a href="#section-4" id="markdown-toc-section-4">清除工作</a></li>
  <li><a href="#section-5" id="markdown-toc-section-5">程序编译</a></li>
  <li><a href="#section-6" id="markdown-toc-section-6">注意事项</a></li>
</ul>

<p><a href="https://ffmpeg.org/">FFmpeg</a> 是制作视频应用或一般工具的非常棒的库。<a href="https://www.libsdl.org/">SDL</a> 通过封装复杂的视音频底层交互工作，降低了视音频的处理难度。</p>

<p>本文就记录一下利用 FFmpeg 和 SDL 制作简单播放器的详细步骤。<!--more--></p>

<h3 id="section">介绍</h3>

<p>对于一个视音频文件，可以从外到内的依次分为几个层面：container、stream、packets、frames.其中 container 就是平时说的<code>.avi</code> <code>.flv</code> <code>.mkv</code>等等。stream可能是 <code>video</code>、可能是 <code>audio</code>、也可能是 <code>subtitle</code>，一个文件里面可能包含多个 <code>video</code> <code>audio</code> <code>subtitle</code>。packets 是从 stream 里得到的，通常会包含一个 <code>video frame</code> 或多个 <code>audio frame</code>。</p>

<p>视音频的处理就是按照这几个层级处理的，以 <code>.avi</code> 为例大概步骤如下：</p>

<pre><code>    1. OPEN video_stream FROM video.avi

    2. READ packet FROM video_stream INTO frame

    3. IF frame NOT COMPLETE GOTO 2

    4. DO SOMETHING WITH frame

    5. GOTO 2
</code></pre>

<p>当然，步骤 4 中的”DO SOMETHING”可能非常复杂，我们先简单的把得到的 frames 写到一个 PPM 文件中。</p>

<hr />

<h3 id="section-1">打开文件</h3>

<p>想要利用FFmpeg，你必须首先初始化库。
{% codeblock lang:c %}
int main(int argc, char *argv[]){
av_register_all();
{% endcodeblock %}
<code>av_register_all()</code>用于注册所有编译过的<code>muxers</code> <code>demuxers</code>和<code>protocols</code>，同时，该函数还会调用<code>avcodec_register_all()</code>注册所有的音视频 codec。</p>

<p>现在就可以打开视频文件了。
{% codeblock lang:c %}
AVFormatContext *pFormatCtx = NULL;</p>

<p>//open video file
if(avformat_open_input(&amp;pFormatCtx, argv[1], NULL, 0, NUL) != 0)
        return -1; //Couldn’t open file
{% endcodeblock %}
调用函数 <code>avformat_open_input</code>,该函数读取文件头部，并将文件的格式信息存储到<code>AVFormatContext</code>结构中。最后的三个参数分别用于指定文件格式、内存大小和格式选项，此处设为<code>NULL</code>或 0，<code>libavformat</code>能够自动侦测到。</p>

<p>该函数只是简单的查看头部信息，接下来我们需要文件中码流的信息：
{% codeblock lang:c %}
//Retrieve stream information
if(avformat_find_stream_info(pFormatCtx, NULL) &lt; 0)
        return -1;      //Couldn’t find stream information
{% endcodeblock %}
该函数用适当的信息填充<code>pFormatCtx-&gt;streams</code>。此处介绍一个便于调试的函数来看一下里面的内容：
{% codeblock lang:c %}
//Dump information about file onto standard error
av_dump_format(pFormatCtx, 0, argv[1], 0);
{% endcodeblock %}
现在<code>pFormatCtx-&gt;streams</code>仅仅是一个数组指针，数组大小为<code>pFormatCtx-&gt;nb_streams</code>,遍历该数组直到找到一个视频流。
{% codeblock lang:c %}
int i;
AVCodecContext *pCodecCtxOrig = NULL;
AVCodecContext *pCodecCtx     = NULL;</p>

<p>//Find the first video stream
videoStream = -1;
for(i = 0; i &lt; pFormatCtx-&gt;nb_streams; i++)
	if(pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type = AVMEDIA_TYPE_VIDEO){
		videoStream = i;
		break;
	}
if(videoStream == -1)
	return -1; //Didn’t find a video stream</p>

<p>// Get a pointer to the codec context for the video stream
pCodecCtxOrig = pFormatCtx-&gt;streams[videoStream]-&gt;codec;
{% endcodeblock %}
关于<code>codec</code>的流信息我们称之为<code>codec context</code>。它包含了关于流使用的该<code>codec</code>的所有信息，并且我们有一个指针指向它。但我们必须找到实际的codec并打开它：
{% codeblock lang:c %}
AVCodec *pCodec = NULL;</p>

<p>// Find the decoder for the video stream
pCodec = avcodec_find_decoder(pCodecCtx-&gt;codec_id);
if(pCodec == NULL){
	fprintf(stderr, “Unsupported codec!\n”);
	return -1;	// Codec not found
}</p>

<p>// Copy context
pCodecCtx = avcodec_alloc_context3(pCodec);
if(avcodecc_copy_context(pCodecCtx, pCodecCtxOrig) != 0){
	fprintf(stderr, “Couldn’t copy codec context”);
	return -1;	// Error copying codec context
}</p>

<p>//Open codec
if(avcodec_open2(pCodecCtx, pCodec) &lt; 0)
	return -1;	// Could not open codec
{% endcodeblock %}
因为不能直接使用视频流的<code>AVCodecContext</code>！因此必须使用<code>avcodec_copy_context()</code>来 copy 该 context 到一个新位置。</p>

<hr />

<h3 id="section-2">存储数据</h3>

<p>现在我们需要一块内存来真实的存储这些帧：
{% codeblock lang:c %}
AVFrame *pFrame = NULL;</p>

<p>//Allocate video frame
pFrame = av_frame_alloc();
{% endcodeblock %}
既然我们想要输出 PPM 文件（被存储为 24-bit RGB），我们必须将帧从它原本格式转换为 RGB。FFmpeg 可以为我们做这种转换。对于大多数项目，会将初始帧转换为特定格式。让我们分配一帧来为转换帧。
{% codeblock lang:c %}
// Allocate an AVFrame structure
pFrameRGB = av_frame_alloc();
if(pFrameRGB == NULL)
	return -1;
{% endcodeblock %}
尽管我们已经分配了帧，仍然需要一块内存存放 raw data 信息。我们使用 avpicture_get_size 来获得我们需要的大小，并手动分配该内存。
{% codeblock lang:c %}
uint8_t *buffer = NULL;
int numBytes;
//Determine required buffer size and allocate buffer
numBytes = avpicture_get_size(PIX_FMT_RGB24, pCodecCtx-&gt;width, pCodecCtx-&gt;height);
buffer = (uint8_t *)av_malloc(numBytes * sizeof(uint8_t));
{% endcodeblock %}
<code>av_malloc</code>是 FFmpeg 的分配函数，它简单封装了 malloc 函数并做内存对齐，并不会保护内存泄漏、多次释放内存或者其他分配问题。</p>

<p>现在我们使用<code>avpicture_fill</code>来将帧和新分配的内存联系起来。关于<code>AVPicture</code>强制转换：<code>AVPicture</code>结构是<code>AVFrame</code>结构体的子集——<code>AVFrame</code>结构的开始对于<code>AVPicture</code>结构来说是唯一的。
{% codeblock lang:c %}
// Assign appropriate parts of buffer to image planes in pFrameRGB
// Note that pFrameRGB is an AVFrame, but AVFrame is a superset of AVPicture
avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24, pCodecCtx-&gt;width, pCodecCtx-&gt;height);
{% endcodeblock %}
最后，我们读取码流。</p>

<hr />

<h3 id="section-3">读取数据</h3>

<p>我们接下来要做的就是通过读<code>packet</code>中的整个视频流，解码到帧，一旦我们的帧完成后，就转换并保存它。
{% codeblock lang:c %}
struct SwsContext *sws_ctx = NULL;
int frameFinished;
AVPacket packet;
// initialize SWS context for software scaling
sws_ctx = sws_getContext(pCodecCtx-&gt;width, pCodecCtx-&gt;height, pCodecCtx-&gt;pix_fmt, pCodecCtx-&gt;width, pCodecCtx-&gt;height, PIX_FMT_RGB24, SWS_BILINEAR, NULL, NULL, NULL);</p>

<p>i = 0;
while(av_read_frame(pFormatCtx, &amp;packet) &gt;= 0){
	// Is this a packet from the video stream?
	if(packet.stream_index == videoStream){
		//Decode video frame
		avcodec_decode_video2(pCodecCtx, pFrame, &amp;frameFinished, &amp;packet);</p>

<pre><code>	//Did we get a video frame?
	if(frameFinished){
		//Convert the image from its native format to RGB
		sws_scale(sws_ctx, (uint8_t const * contst *)pFrame-&gt;data, pFrame-&gt;linesize, 0, pCodecCtx-&gt;height, pFrameRGB-&gt;data, pFrameRGB-&gt;linesize);
		
		// Save the frame to disk
		if(++i &lt;= 5)
		SaveFrame(pFrameRGB, pCodecCtx-&gt;widht, pCodecCtx-&gt;height, i);
	}
}
// Free the packet that was allocated by av_read_frame
av_free_packet(&amp;packet); } {% endcodeblock %}
</code></pre>

<p>这一过程仍然比较简单：<code>av_read_frame</code> 读取<code>packet</code>并把它保存到<code>AVPacket</code>结构体内。注意我们已经分配了<code>packet</code>结构体，它是用<code>packet.data</code>指针指出的，它由<code>av_free_packet</code>释放。<code>avcodec_decode_video</code>将<code>packets</code>转换为<code>frame</code>。最后，使用<code>sws_scale</code>转换原始格式为<code>RGB</code>。记住，你可以将<code>AVFrame</code>强制类型转换为<code>AVPicture</code>指针。最后要做的就是把<code>frame</code>和宽高信息传递给<code>SaveFrame</code>函数。</p>

<p>{% codeblock lang:c %}
void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame){
    FILE *pFile;
    char szFilename[32];
    int y;</p>

<pre><code>//Open file
sprintf(szFilename, "frame%d.ppm", iFrame);
pFile = fopen(szFilename, "wb");
if(pFile == NULL)
    return;

//Wirte header
fprintf(pFile, "P6\n%d %d\n255\n", width, height);

//Write piexl data
for(y = 0; y &lt; height; y++)
    fwrite(pFrame-&gt;data[0] + y*pFrame-&gt;linesize[0], 1, width*3, pFile);

//Close file
fclose(pFile); } {% endcodeblock %}
</code></pre>

<h3 id="section-4">清除工作</h3>

<p>{% codeblock lang:c %}
//Free the RGB image
av_free(buffer);
av_free(pFrameRGB);</p>

<p>//Free the YUV frame
av_free(pFrame);</p>

<p>//Close the codecs
avcodec_close(pCodecCtx);
avcodec_close(pCodecCtxOrig);</p>

<p>//Close the video file
avformat_close_input(&amp;pFormatCtx);</p>

<p>return 0;
{% endcodeblock %}</p>

<h3 id="section-5">程序编译</h3>

<p><code>
gcc -o tutorial01 tutorial01.c -lavutil -lavformat -lavcodec -lswscale -lz -lm
</code></p>

<h3 id="section-6">注意事项</h3>

<p>本文主要参考<code>FFmpeg</code>官方文档<a href="http://dranger.com/ffmpeg/tutorial01.html">An ffmpeg and SDL Tutorial</a>, 改动有：</p>

<p>1.将其中的<code>PIX_FMT_RGB24</code>改为<code>AV_PIX_FMT_RGB24</code>;</p>

<p>2.编译选项添加了<code>-lswscale</code>。</p>

<p>3.Get a pointer to the codec context for the video stream 时，应将其 codec 赋给<code>pCodecCtxOrig</code>而不是<code>pCodecCtx</code>。</p>

]]></content>
  </entry>
  
</feed>
