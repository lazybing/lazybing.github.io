---
layout: post
title: "OverView of HEVC Standard"
date: 2021-10-16 06:48:21 -0700
comments: true
categories: HEVC
---

* list element with functor item
{:toc}

HEVC 是 ITU-T 视频编码专家组和 ISO/IEC 运动图像专家组的最新视频编码标准。HEVC 标准化工作的主要目标是相对于现有标准，在 50% 的比特率降低范围内显著提高压缩性能，以获得相同的感知视频质量。本文概述了 HEVC 标准的技术特性和特点。

<!--more-->

## 介绍

HEVC 标准是 ITU-T 视频编码专家组(VCEG)和 ISO/IEC 运动图像专家组(MPEG)标准化组织的最新联合视频项目，它们在一个称为视频编码联合协助小组(JCT-VC)的伙伴组织关系中共同工作。HEVC 标准的第一版预计将于 2013 年 1 月定稿，最终形成一份由 ITU-T 和 ISO/IEC 共同发布的统一文本。后续会有更多工作，以扩展该标准，从而支持多个其他应用场景，包括具有增强精度和颜色格式支持的扩展范围使用、可伸缩视频编码和三维/立体/多视图视频编码。在 ISO/IEC 中，HEVC标准将成为 MPEG-H 第 2 部分(ISO/IEC 23008-2)，在 ITU-T 中，它很可能成为 ITU-T 建议 H.265。

视频编码标准主要通过注明的 ITU-T 和 ISO/IEC 标准的发展而起来的。ITU-T 生产了 H.261 和 H.263，ISO/IEC 生产了 MPEG-1 和 MPEG-4视频，这两个组织联合生产了 H.262/MPEG-2视频和 H.264/MPEG-4 AVC 标准。这两项联合制定的标准产生了特别强烈的影响，并已被广泛应用于我们日常生活中日益流行的各种产品中。在这一演变过程中，不断努力最大限度地提高压缩能力，并改进其他特性，如数据丢失鲁棒性，同时考虑到在预期部署每个标准时，产品中实际使用的计算资源。

HEVC 之前的主要视频编码标准是 H.264/MPEG-4 AVC，它最初是在 1999 年至 2003 年期间开发的，然后在 2003 年至 2009 年期间以几种重要方式进行了扩展。H.264/MPEG-4 AVC 是数字视频的一种使能技术，几乎涵盖了 H.262/MPEG-2 视频之前未涵盖的所有领域，并在其现有应用领域中基本上取代了旧标准。它广泛应用于许多应用，包括通过卫星、有线和地面传输系统广播高清(HD)电视信号、视频内容采集和编辑系统、摄像机、安全应用、互联网和移动网络视频、蓝光光盘以及视频聊天等实时对话应用，视频会议和远程呈现系统。

然而，服务的日益多样化、高清视频的日益普及以及超高清格式(如4kx2k 或 8kx4k分辨率)的出现，对编码效率的需求甚至超出了 H.264/MPEG-4 AVC 的能力。当更高的分辨率伴随立体声或多视图捕获和显示时，这种需求更强烈了。此外，针对移动设备和平板电脑的视频应用程序所带来的流量，以及视频点播服务的传输需求，正在给当今的网络带来严峻挑战。在移动应用程序中，对更高质量和分辨率的需求也越来越强烈。

HEVC 旨在解决 H.264/AVC 的所有现有应用，并特别关注两个特别问题：提高视频分辨率，增加并行处理框架的使用。HEVC 的语法是通用的，通常也适用于上面没有特别提到的其他应用程序。

与过去所有的 ITU-T 和 ISO/IEC 视频编码标准一样，在 HEVC 中，只有比特流结构和语法是标准化的，并且对生产解码图片的比特流及其映射的约束也是标准化的。通过定义语法元素的语义和解码过程来给出映射，使得当给定符合标准约束的比特流时，符合标准的每个解码器将产生相同的输出。标准范围的这种限制允许以适合特定应用的方式(平衡压缩质量、实现成本、上市时间和其他考虑因素)最大限度地优化实现。然而，它并不能保证端到端的复制质量，因为它甚至允许有损失的编码技术被认为是合格的。

为了帮助行业社区学习如何使用标准，标准化工作不仅包括开发文本规范文档，还包括参考软件源代码，作为如何编码和解码 HEVC 视频的示例。在标准设计期间，参考软件草案已被用作委员会内部工作的研究工具，也可作为通用研究工具和产品基础，还正在开发标准测试数据套件，以测试是否符合该标准。

本文的组织结构如下：第二部分重点介绍 HEVC 编码设计的一些关键特性。第三部分解释了 HEVC 编码数据的高级语法和总体结构。第四部分将更详细地描述 HEVC 编码技术。第五部分解释了 HEVC 的 profile、tier 和 level 设计。由于编写像  HEVC 这样实质性的技术概述需要大量的总结，如有遗漏，请向读者咨询。第六部分讨论了 HEVC 标准化工作的历史。

## HEVC 编码设计和功能亮点

HEVC 标准旨在实现多个目标，包括编码效率、易于传输系统集成和数据丢失恢复能力，以及使用并行处理架构的可实现性。下面小节简要描述了实现这些目标的设计关键要素，以及生成有效比特流的典型编码器操作。第三节和第四节提供了有关不同元素的相关语法和解码过程的更多细节。

### A. 视频编码层

HEVC 的视频编码层采用自 H.261 以来所有视频压缩标准中使用的相同的混合编码方法(图像间/图像内预测和二维变换编码)。图 1 描述了可创建符合 HEVC 标准的比特流的混合视频编码器的框图。

产生符合 HEVC 的比特流的编码算法通常如下进行：每个图片被分割成块形区域，精确的块分割被传送到解码器。视频序列的第一幅图片(以及每个随机接入点处的第一幅图片到视频序列中)仅使用图片内预测进行编码(该预测使用同一图片内从区域到区域的空间数据预测，但不依赖于其他图片)。对于序列或随机接入点间的所有剩余图片，通常对大多数块使用图像间时间预测编码模式。用于画面间预测的编码处理包括：选择包含所选参考画面和运动矢量(MV)的运动数据，以应用于预测每个块的样本。编码器和解码器通过使用 MV 和模式决策数据应用运动补偿(MC)来生成相同的图像间预测信号，这些数据作为边信息传输。

帧内或帧间预测的残余信号(即原始块与其预测之间的差值)，通过线性空间变换进行变换。然后对变换系数进行缩放、量化、熵编码，并与预测信心一起传输。

编码器复制解码器处理循环(参见图1中的灰色阴影框)，以便两者将为后续数据生成相同的预测。因此，量化变换系数通过逆缩放构造，然后逆变换以复制剩余信号的解码近似。然后将残差添加到预测中，并且该添加的结果随后可被反馈到一个或两个环路滤波器中以平滑由分块处理和量化引起的伪影。最终图片表示(即解码器输出的副本)存储在解码图片缓冲器中，以用于后续图片的预测。一般来说，图片的编码或解码处理顺序通常不同于它们从源到达的顺序，需要区分解码器的解码顺序(即比特流顺序)和输出顺序(即显示顺序)。

要由 HEVC 编码的视频材料通常应作为逐行扫描图像输入(由于源视频以该格式产生，或由编码前去交错)。HEVC 设计中不存在明确的编码特征，以支持隔行扫描的使用，因为隔行扫描不再用于显示，并且在分发中变得越来越步常见。然而，在 HEVC 中提供了元数据语法，以允许编码器通过将隔行扫描视频的每个字段(即，每个视频帧的偶数或奇数行)编码以单独图片来指示隔行扫描视频已被发送，或这其已通过将每个隔行扫描帧编码为 HEVC 编码图片来发送。这提供了一种对隔行视频进行编码的有效方法，而无需使解码器负担对其支持特殊解码过程的负担。

在下文中，使用 HEVC 的混合视频编码所涉及的各种特性如下所示。

#### 1) Coding tree units and coding tree block(CTB) structure

在以前的标准中，编码层的核心是宏块，它包含 luma 采样的 16x16 宏块，在通常的 4:2:0 颜色采样情况下，chroma 采样有对应的 8x8 色度块；而 HEVC 中的类似结构是编码树单元(CTU)，其大小由编码器选择，可以大于传统宏块。CTU 由 luma CTB 和对应的色度 CTB 以及语法元素组成。luma CTB 的大小可以选择为 L=16、32或64个样本，较大的大小通常能够实现更好的压缩。HEVC 支持使用树结构和类似四叉树的信令将 CTB 划分为更小的块。

#### 2）Coding units(CUs) and coding blocks(CBs)

CTU 的四叉树语法指定其亮度和色度 CBs 的大小和位置。四叉树的根与 CTU 关联。因此，luma CTB 的大小是 luma CB 支持的最大大小。CTU 分为 luma 和 chroma CBs 是联合发出的信号。一个 luma CB 和两个 sample CB，连同相关的语法，构成一个编码单元(CU)。一个 CTB 可以只包含一个 CU，或者可以分割成多个 CU，并且每个 CU 都有一个相关的分区为预测单元(PU)和变换单元树(TU)。

#### 3）Prediction units and prediction blocks(PBs)

在 CU 级别决定是使用图像间预测还是图像内预测对图片区域进行编码。PU 分区结构的根位于 CU 级别。取决于基本预测类型决策，luma 和 chroma CBs 随后可以在大小上进一步分割并从 luma 和 chroma 预测块(PBs)预测。HEVC 支持从 64x64 到 4x4 样本的可变 PB 大小。

#### 4）TUs and transform blocks

使用块变换对预测残差进行编码。TU 树结构的根位于 CU 级别。luma CB 残差可以与 luma 变换块(TB)相同，或者可以进一步分割成更小的 luma TB。这同样适用于 chroma TBs。对于 4x4、8x8、16x16 和 32x32 的正方形 TB，定义了与DCT 类似的整数基函数。对于 luma 图像内预测残差的 4x4 变换，可选指定从 DST 形式导出的整数变换。

#### 5）Motion vector signaling

使用AMVP(Advanced motion vector prediction)，包括基于来自相邻 PBs 和参考图片的数据导出几个最可能的候选。还使用 MV 编码的合并模式，允许 MV 从时间上或空间上相邻的 PBs 继承。此外，与 H.264/AVC 相比，还指定了改进的 skipped 和 直接运动推断。

#### 6）Motion compensation

MVs 使用四分之一采样精度，分数采样位置的插值使用 7 抽头或 8 抽头滤波器(相比之下，H.264/AVC 中，半采样位置的六抽头滤波后，四分之一采样位置的线性插值)。与 H.264/AVC 类似，使用了多个参考图片。对于每个 PB，传输一个或两个运动矢量，分别表示单预测或双预测编码。如在 H.264/AVC 中一样，可以称为加权预测的方式对预测信号应用缩放和偏移操作。

#### 7) Intrapicture prediction

相邻块的间边界样本，用作未执行帧间预测的区域中的空间预测的参考数据。图像内预测支持 33 种方向模式(与 H.264/AVC 中的 8 种模式相比)，以及plus plannr 和 DC 预测模式。通过基于先前解码的相邻 PBs 的模式导出最可能模式(例如，预测方向)来编码所选择的画面内预测模式。

#### 8) Quantization control

与 H.264/AVC 中一样，HEVC 中使用均匀重建量化(URQ)，量化缩放矩阵支持各种变换块大小。

#### 9）Entropy coding

CABAC 用于熵编码。这类似于 H.264/AVC 中的 CABAC 方案，单经过几次改进以提高其吞吐量速度(特别是对于并行处理架构)和压缩性能，并降低其上下文内存需求。

#### 10）In-loop deblocking filtering

与 H.264/AVC 中使用的去块滤波器类似去块滤波器，在图像间预测循环中操作。然而，该设计在决策和过滤过程方面得到了简化，并且对并行处理更加友好。

#### 11）Sample adaptive offset(SAO)

在去块滤波器之后，在图像间预测环路中引入非线性振幅映射。它的目标是通过使用查找表更好地重建原始信号振幅，该查找表由几个附加参数描述，这些参数可以通过编码器端的直方图分析确定。

### B. 高级语法体系结构

HEVC 标准新增的许多设计方面，提高了在各种应用程序和网络环境下操作的灵活性，并提高了数据丢失的鲁棒性。然而，H.264/AVC 标准中使用的高级语法体系结构通常被保留，包括以下特征。

#### 1）Parameter set structure

参数集包含可共享的信息，用于解码解码视频的多个区域。参数集结构提供了用于传输解码过程所必需的数据的健壮机制。通过一种新的 VPS 结构，对 H.264/AVC 中的序列和图片参数集的概念进行了扩充。

#### 2）NAL unit syntax structure

每个语法结构都被放入 NAL 单元的逻辑数据包中。使用两个字节 NAL 单元报头的内容，可以容易地识别相关有效负载数据的用途。

#### 3）Slices

slice 是一种数据结构，在熵编码、信号预测和残差信号重建方面，可以独立于同一图片的其他 slice 进行解码。slice 可以是整个图片，也可以是图片中的一个区域。slice 的主要用途之一是在数据丢失时重新同步。在分组传输的情况下， slice 内有效负载比特的最大数量通常受到限制，并且 slice 中 CTU 的数量经常变化以最小化分组开销，同时将每个分组的大小保持在此范围内。

#### 4）SEI 和 VUI

该语法元素支持各种类型元数据，比如 SEI 和 VUI。这些数据提供关于视频图片的定时、视频信号中使用的颜色空间的正确解释、三维立体帧打包信息、其他显示提示信息等的信息。

### C. 并行解码语法与改进的 slice 结构

最后，HEVC 标准中引入了四个新的特性，以增强并行处理能力或修改 slice 数据的结构以实现打包。它们中的每一个在特定的应用环境中都可能有好处，并且通常由编码器或解码器的实现者来确定是否以及如何利用这些特性。

#### 1） Tiles

Tiles 作为标准的可选项，它将图片分割为矩形区域。Tiles 的主要目的是增加并行处理能力，而不是提供错误恢复能力。Tiles 是图片的独立可解码区域，它使用一些共享头信息进行编码。Tiles 还可用于视频图片局部区域的空间随机访问。图片的典型 tile 配置将图片分割为矩形区域，每个 tiles 中的 CTU 数量大致相等。Tiles 提供了并行性的更粗粒度级别，并且线程的使用不需要复杂的同步。

#### 2）Wavefront parallel processing(WPP)

当启动波前并行处理(WPP)时，一个 slice 被划分为若干行 CTU。第一行以普通方式处理，第二行可以在第一行仅处理两个 CTU 后开始处理，第三行可以在第二行仅处理两个 CTU 后开始处理，以此类推。每一行中熵编码器的上下文模型是根据前一行中具有两个 CTU 处理延迟的上下文模型推到出来的。WPP 在相当精细的粒度级别上提供了一种处理并行性的形式，即在一个 slice 内。WPP 通常可以提供比 Tiles 更好的压缩性能(并避免使用 Tiles 可能导致的一些视觉瑕疵)。

#### 3）Dependent slice segments

一种称为 Dependent Slice Segment 的结构，允许在单独的 NAL 单元中携带与特定波前入口点或 Tiles 相关的数据，因此，与将数据全部编码在一个 slice 中相比，该结构有可能使该数据以更低的延迟提供给分片打包系统。波前入口点的 Dependent Slice Segments 只能在另一 slice 的解码过程的至少一部分已经执行之后进行解码。相关 slice 主要用于低延迟编码，其他并行工具可能会影响压缩性能。

接下来的两个部分中，将对主要功能进行更详细的描述。






